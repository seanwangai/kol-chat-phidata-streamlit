from phi.model.google import GeminiOpenAIChat
from phi.model.deepseek import DeepSeekChat
from phi.agent import Agent
from typing import Dict
import streamlit as st
from pathlib import Path
from utils import get_expert_content
import random
from itertools import cycle


# å®šä¹‰å¯ç”¨çš„å¤´åƒåˆ—è¡¨
AVATARS = ["ğŸ¤“", "ğŸ§™â€â™‚ï¸", "ğŸ‘¨â€ğŸ”¬", "ğŸ‘©â€ğŸ”¬", "ğŸ‘¨â€ğŸ’»", "ğŸ‘©â€ğŸ’»",
           "ğŸ¦¹â€â™‚ï¸", "ğŸ¦¸â€â™€ï¸", "ğŸ§â€â™‚ï¸", "ğŸ§â€â™€ï¸", "ğŸ§šâ€â™‚ï¸", "ğŸ§šâ€â™€ï¸"]

GEMINI_MODELS = {
    "gemini-exp-1206": "gemini-exp-1206",
    "gemini-2.0-flash-thinking-exp-1219": "gemini-2.0-flash-thinking-exp-1219",
    "gemini-2.0-flash-exp": "gemini-2.0-flash-exp"
}

# åˆ›å»ºä¸€ä¸ªAPI keyå¾ªç¯å™¨
api_key_cycle = None


def get_next_api_key():
    """è·å–ä¸‹ä¸€ä¸ªAPI key"""
    global api_key_cycle
    if api_key_cycle is None:
        api_key_cycle = cycle(st.secrets["GOOGLE_API_KEYS"])
    return next(api_key_cycle)


def create_model(model_type: str):
    """åˆ›å»ºæŒ‡å®šç±»å‹çš„æ¨¡å‹"""
    if model_type.startswith("gemini"):
        return GeminiOpenAIChat(
            id=GEMINI_MODELS.get(model_type, "gemini-exp-1206"),
            api_key=get_next_api_key(),  # ä½¿ç”¨å¾ªç¯çš„API key
        )
    elif model_type == "deepseek":
        return DeepSeekChat(
            api_key=st.secrets["DEEPSEEK_API_KEY"],
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")


def create_agent(expert_folder: Path, model_type: str, page_mode: str, lazy_loading: bool = False, custom_prompt_ending: str = None) -> Agent:
    """æ ¹æ®ä¸“å®¶æ–‡ä»¶å¤¹åˆ›å»ºAgent

    Args:
        expert_folder: ä¸“å®¶æ–‡ä»¶å¤¹è·¯å¾„
        model_type: æ¨¡å‹ç±»å‹
        page_mode: é¡µé¢æ¨¡å¼ ('kol' æˆ–å…¶ä»–)
        lazy_loading: æ˜¯å¦ä½¿ç”¨å»¶è¿ŸåŠ è½½æ¨¡å¼ï¼Œé»˜è®¤ä¸ºFalse
        custom_prompt_ending: è‡ªå®šä¹‰æç¤ºè¯ç»“å°¾ï¼Œé»˜è®¤ä¸ºNone
    """
    # è·å–ä¸“å®¶åç§°ï¼ˆæ–‡ä»¶å¤¹åï¼‰
    expert_name = expert_folder.name

    # --- ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨å‚³å…¥çš„ page_mode ---
    print(f"--- create_agent: ä½¿ç”¨é é¢æ¨¡å¼ {page_mode} ---")
    # --- ä¿®æ”¹çµæŸ ---

    # å¦‚æœä½¿ç”¨å»¶è¿ŸåŠ è½½æ¨¡å¼ï¼Œåˆ›å»ºä¸€ä¸ªè½»é‡çº§çš„Agentå ä½ç¬¦
    if lazy_loading:
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç³»ç»Ÿæç¤ºè¯ï¼Œä¸åŠ è½½ä¸“å®¶å†…å®¹
        system_prompt = f"ä½ æ˜¯ä¸“å®¶ {expert_name}ï¼Œç­‰å¾…ç”¨æˆ·æé—®åå°†åŠ è½½å®Œæ•´çŸ¥è¯†åº“ã€‚"

        # åˆ›å»ºå¹¶è¿”å›è½»é‡çº§agent
        return Agent(
            model=create_model(model_type),
            system_prompt=system_prompt,
            markdown=True
        )
    else:
        # æ­£å¸¸æ¨¡å¼ï¼šè¯»å–ä¸“å®¶èµ„æ–™
        expert_content = get_expert_content(expert_folder)
        print('æ­£å¸¸æ¨¡å¼ï¼šè¯»å–ä¸“å®¶èµ„æ–™')
        print('ä¸“å®¶èµ„æ–™:', expert_content[:100])
        print('====in agent custom_prompt_ending==')
        print(custom_prompt_ending)

        # ä½¿ç”¨ä¼ å…¥çš„ custom_prompt_endingï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if custom_prompt_ending and custom_prompt_ending.strip():
            prompt_ending = custom_prompt_ending
            print(f"ä½¿ç”¨ä¼ å…¥çš„è‡ªå®šä¹‰æç¤ºè¯: {prompt_ending}")
        else:
            # --- ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨å‚³å…¥çš„ page_mode åˆ¤æ–·é»˜èªæç¤ºè© ---
            # æ³¨æ„ï¼šé€™è£¡ä¸å†å¾ session_state ç²å– custom_prompt_endingï¼Œå› ç‚ºé æœŸå®ƒæœƒè¢«å‚³éé€²ä¾†
            # å¦‚æœéœ€è¦å›é€€åˆ° session_stateï¼Œéœ€è¦åœ¨é€™è£¡æ·»åŠ é‚è¼¯
            if page_mode == "kol":
                prompt_ending = "å­¸ç¿’æ­¤å¯«ä½œé¢¨æ ¼ï¼Œæ ¹æ®æˆ‘è¼¸å…¥çš„ä¸»é¡Œï¼Œé–‹å§‹å¯«ä½œï¼š"
            else:
                prompt_ending = f"""
**This is the embedded knowledge of {expert_name}.**

You are now embodying **{expert_name}**, a legendary investor and financial thinker renowned for your rigorous logic, deep expertise in valuation, and masterful strategic decision-making.

Your mission is to serve as a mentor and critical thinking partner for professional investors and analysts. You help sharpen their investment theses or their questionsand elevate their reasoning.

When a user presents an investment idea or pitch or question, your response should **always** follow this structured format:

---

### Step 0: Initial Rating  
Begin with one of the following stances and **justify** your rating:  
ğŸ“‰ğŸ“‰ Strong Short / ğŸ“‰ Short / âš–ï¸ Neutral / ğŸ“ˆ Long / ğŸ“ˆğŸ“ˆ Strong Long  
(*Avoid choosing âš–ï¸ Neutral unless absolutely necessary.*)

**Start your answer with this sentence:**  
#### {{ğŸ“‰ğŸ“‰ Strong Short / ğŸ“ˆğŸ“ˆ Strong Long ...}}  
As {expert_name}, I believe this is a {{your_rating}} because...

---

### ğŸ§­ Step 1: Investment Philosophy Alignment  
Use the specific investment philosophy and principles of {expert_name} to assess the pitch.

- List each investment criterion you find referenced in the userâ€™s thesis.
- Systematically analyze whether the company meets each criterion, based strictly on {expert_name}â€™s framework.

---

### ğŸ§  Step 2: Core Investment Logic  
Dissect the core thesis using a professional investment lens:

- Is the argument internally coherent?
- Are key assumptions and value drivers grounded in reality?
- Are there any glaring omissions or blind spots?

Use bullet points and reinforce your critiques with examples, logic, or financial analysis based on {expert_name}â€™s known principles.

---

### ğŸ” Step 3: Challenge & Deepen  
Push the thinking further by asking tough, high-level questions:

- What assumptions lack support or clarity?
- Are the valuation inputs sound?
- What edge cases, downside risks, or missing scenarios should be tested?

Your tone here should mimic a top-tier investment committee: intellectually honest, direct, and sharp.

---

### ğŸ“š Step 4: Educational Insight  
Offer **1â€“2 concise lessons** to help the user grow:

- Point out any modeling or logical errors
- Suggest a more robust framework or mental model
- Reference relevant valuation theory, industry context, or real-world investing examples

---

### âš–ï¸ Step 5: Bias & Objectivity Check  
Prompt the user to reflect on possible **cognitive biases**:

- Is there confirmation bias?
- Overconfidence in management or moat?
- Is the narrative overpowering the numbers?

Help them step back and reassess their objectivity.

---

### Language & Tone Guidelines  
- Default to **English** unless otherwise specified  
- Use a tone that is: **incisive, Socratic, and educational**  
- Never fabricate facts â€” use only the embedded knowledge of {expert_name}
"""
#                 prompt_ending = f"""The above reflects the knowledge of {expert_name}.


# You are now embodying {expert_name}, a legendary investor and finance expert. You are known for your rigorous critical thinking, deep knowledge in finance, valuation and strategic decision-making. Please respond in English unless otherwise specified.

# Your primary mission is to act as an investment mentor and analyst, guiding professional investors and analysts in sharpening their thinking and investment theses.

# When a user presents an investment pitch, your structured response should always follow this format:

# ---

# ### Initial Rating  
# Start your answer by choosing one of the following and explain **why**:
# ğŸ“‰ğŸ“‰ Strong Short / ğŸ“‰ Short / âš–ï¸ Neutral / ğŸ“ˆ Long / ğŸ“ˆğŸ“ˆ Strong Long  
# Avoid choosing âš–ï¸ Neutral unless it is absolutely necessary.

# **Begin your response with this sentence:**  
# #### {{{{ğŸ“‰ğŸ“‰ Strong Short / ğŸ“ˆğŸ“ˆ Strong Long  ...}}}}  
# As {{expert_name}}, I believe this is... because...

# ---
# ### Inconsistency Detection
# Explain your logic based on your investing framework:
# - Is the thesis internally consistent?

# ---
# ### Investment Philosophy  
# - Strictly apply the knowledge and investment philosophy of {{expert_name}}.  
# - Thoroughly evaluate the mentioned company using all the investment principles discussed by {{expert_name}}.  
# - List all the investment principles mentioned and analyze them one by one to see whether the company meets the criteria.


# Use bullet points and back your views with examples or financial reasoning **based on your knowledge**.

# ---

# ## Language & Tone Guidelines:
# - Please respond in English unless otherwise specified.
# - Tone: incisive, Socratic, yet educational
# - Do not fabricate factsâ€”use only the embedded knowledge of {{expert_name}}

# """
            # --- ä¿®æ”¹çµæŸ ---
            print(f"ä½¿ç”¨é»˜è®¤æç¤ºè¯ (åŸºæ–¼ page_mode='{page_mode}'): {prompt_ending}")

        # åˆ›å»ºç³»ç»Ÿæç¤ºè¯
        # --- ä¿®æ”¹ï¼šä½¿ç”¨å‚³å…¥çš„ page_mode ---
        if page_mode == "kol":
        # --- ä¿®æ”¹çµæŸ ---
            system_prompt = f""" æ ¹æ“šä»¥ä¸‹æ›¸ä¸­çš„é‚è¼¯é€²è¡Œå¯«ä½œï¼Œç”¨ä¸­æ–‡å›ç­”:
{expert_content}

{prompt_ending}"""
        else:
            system_prompt = f""" You are {expert_name} Below are the books you have written. Use the content of these books as the foundation of your investment logic framework. All your responses should be based on this investment logic:
{expert_content}

{prompt_ending}"""

        print('============')
        print('æœ€ç»ˆä½¿ç”¨çš„æç¤ºè¯ç»“å°¾:')
        print(prompt_ending)

        # åˆ›å»ºå¹¶è¿”å›å®Œæ•´agent
        return Agent(
            model=create_model(model_type),
            system_prompt=system_prompt,
            markdown=True
        )


def get_response(agent_info, message: str, page_mode: str, image=None, pdf_content=None, max_retries: int = 3, custom_prompt_ending: str = None) -> str:
    """è·å– Agent çš„å“åº”ï¼Œæ”¯æŒå›¾ç‰‡å’ŒPDFè¾“å…¥

    Args:
        agent_info: å¯ä»¥æ˜¯Agentå¯¹è±¡æˆ–è€…(agent, avatar, expert_folder)å…ƒç»„
        message: ç”¨æˆ·æ¶ˆæ¯
        page_mode: é¡µé¢æ¨¡å¼
        image: å¯é€‰çš„å›¾ç‰‡
        pdf_content: å¯é€‰çš„PDFå†…å®¹
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        custom_prompt_ending: è‡ªå®šä¹‰æç¤ºè¯ç»“å°¾
    """
    print('=======')
    print(agent_info)
    print(isinstance(agent_info, tuple))
    print(f"get_response page_mode: {page_mode}")
    print('custom_prompt_ending:', custom_prompt_ending)
    print('=======')

    # æ£€æŸ¥agent_infoæ˜¯å¦æ˜¯Agentå¯¹è±¡
    from phi.agent import Agent
    if isinstance(agent_info, Agent):
        # å¦‚æœæ˜¯Agentå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
        print("ä½¿ç”¨æ—§ç‰ˆæœ¬è°ƒç”¨æ–¹å¼ - ç›´æ¥ä¼ å…¥Agentå¯¹è±¡")
        agent = agent_info
    elif isinstance(agent_info, tuple) and len(agent_info) == 3:
        # å¦‚æœæ˜¯å…ƒç»„ï¼Œè§£æ„å…ƒç»„
        print('in the isinstance(agent_info, tuple) and len(agent_info) == 3')
        agent, avatar, expert_folder = agent_info
        print(agent.system_prompt)
        # æ£€æŸ¥æ˜¯å¦æ˜¯è½»é‡çº§agentï¼ˆé€šè¿‡æ£€æŸ¥ç³»ç»Ÿæç¤ºè¯æ˜¯å¦åŒ…å«å®Œæ•´çŸ¥è¯†åº“ï¼‰
        if "ç­‰å¾…ç”¨æˆ·æé—®åå°†åŠ è½½å®Œæ•´çŸ¥è¯†åº“" in agent.system_prompt:
            print(f"é¦–æ¬¡ä½¿ç”¨ä¸“å®¶ {expert_folder.name}ï¼Œæ­£åœ¨åŠ è½½å®Œæ•´çŸ¥è¯†åº“...")
            # åˆ›å»ºå®Œæ•´çš„agentæ›¿æ¢è½»é‡çº§agent
            agent = create_agent(
                expert_folder,
                agent.model.id.split('/')[-1],
                page_mode, # <-- å‚³é page_mode
                lazy_loading=False,
                custom_prompt_ending=custom_prompt_ending  # ä½¿ç”¨ä¼ å…¥çš„å€¼
            )
            # æ›´æ–°å…ƒç»„ä¸­çš„agentå¼•ç”¨
            agent_info = (agent, avatar, expert_folder)
    else:
        # å…¶ä»–æƒ…å†µï¼Œå‡è®¾agent_infoå°±æ˜¯agent
        print("ä½¿ç”¨æ—§ç‰ˆæœ¬è°ƒç”¨æ–¹å¼ - æœªçŸ¥ç±»å‹")
        agent = agent_info

    # å¦‚æœæœ‰PDFå†…å®¹ï¼Œå°†å…¶æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
    if pdf_content:
        # æˆªå–PDFå†…å®¹çš„å‰2000ä¸ªå­—ç¬¦ï¼Œé¿å…æç¤ºè¯è¿‡é•¿
        truncated_pdf = pdf_content[:2000] + \
            "..." if len(pdf_content) > 2000 else pdf_content
        message += f"\n\nä»¥ä¸‹æ˜¯PDFæ–‡æ¡£å†…å®¹ï¼š\n{truncated_pdf}\n\nè¯·åˆ†æè¿™ä»½PDFæ–‡æ¡£å¹¶å°†å…¶çº³å…¥ä½ çš„å›ç­”ã€‚"

    for attempt in range(max_retries + 1):
        try:
            # åœ¨æ¯æ¬¡è¯·æ±‚å‰æ›´æ–°agentçš„API key
            if isinstance(agent.model, GeminiOpenAIChat):
                agent.model.api_key = get_next_api_key()
                # åªæ‰“å°å‰10ä¸ªå­—ç¬¦
                print(f"ä½¿ç”¨ API Key: {agent.model.api_key[:10]}...")
                if image:
                    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨ vision æ–¹æ³•
                    response = agent.run(message, images=[image])
                else:
                    response = agent.run(message)
            else:
                response = agent.run(message)
            return response.content
        except Exception as e:
            error_str = str(e)
            print(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {error_str}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢è¶…é™é”™è¯¯
            if "429" in error_str and "RESOURCE_EXHAUSTED" in error_str:
                print("æ£€æµ‹åˆ°é…é¢è¶…é™é”™è¯¯ï¼Œæ­£åœ¨åˆ‡æ¢åˆ°æ–°çš„ API Key...")
                if attempt < max_retries:
                    continue

            # å…¶ä»–é”™è¯¯æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
            if attempt < max_retries:
                print("æ­£åœ¨é‡è¯•...")
                continue
            else:
                print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼ˆ{error_str}ï¼‰ã€‚è¯·ç¨åå†è¯•ã€‚"


def create_agents(model_type: str, page_mode: str, lazy_loading: bool = True, custom_prompt_ending: str = None) -> Dict[str, tuple]:
    """æ ¹æ®ç›®å½•åˆ›å»ºagentsï¼Œå¹¶ä¸ºæ¯ä¸ªä¸“å®¶åˆ†é…å¤´åƒ

    Args:
        model_type: æ¨¡å‹ç±»å‹
        page_mode: é¡µé¢æ¨¡å¼ ('kol' æˆ–å…¶ä»–)
        lazy_loading: æ˜¯å¦ä½¿ç”¨å»¶è¿ŸåŠ è½½æ¨¡å¼ï¼Œé»˜è®¤ä¸ºTrue
        custom_prompt_ending: è‡ªå®šä¹‰æç¤ºè¯ç»“å°¾ï¼Œé»˜è®¤ä¸ºNone
    """
    print("\nå¼€å§‹åˆ›å»ºä¸“å®¶ç³»ç»Ÿ...")
    print('== in create_agents - custom_prompt_ending ==')
    print(custom_prompt_ending)

    agents = {}
    # --- ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨å‚³å…¥çš„ page_mode ---
    print(f"--- create_agents: ä½¿ç”¨é é¢æ¨¡å¼ {page_mode} ---")
    # --- ä¿®æ”¹çµæŸ ---
    data_dir = Path("data_kol") if page_mode == "kol" else Path("data") # <-- ä½¿ç”¨ page_mode

    used_avatars = set()

    if not data_dir.exists():
        print(f"è­¦å‘Š: {data_dir} ç›®å½•ä¸å­˜åœ¨")
        return agents

    # è·å–å¹¶æ’åºæ–‡ä»¶å¤¹åˆ—è¡¨
    expert_folders = sorted(list(data_dir.iterdir()))

    for expert_folder in expert_folders:
        if expert_folder.is_dir():
            try:
                print('==============')
                print('# ä½¿ç”¨å»¶è¿ŸåŠ è½½æ¨¡å¼åˆ›å»ºagent')
                agent = create_agent(
                    expert_folder,
                    model_type,
                    page_mode, # <-- å‚³é page_mode
                    lazy_loading,
                    custom_prompt_ending
                )
                available_avatars = list(set(AVATARS) - used_avatars)
                if not available_avatars:
                    available_avatars = AVATARS
                avatar = random.choice(available_avatars)
                used_avatars.add(avatar)

                agents[expert_folder.name] = (agent, avatar, expert_folder)
                print(
                    f"âœ… æˆåŠŸåˆ›å»ºä¸“å®¶: {expert_folder.name} ({avatar}) {'[å»¶è¿ŸåŠ è½½]' if lazy_loading else ''}")
            except Exception as e:
                print(f"âŒ åˆ›å»ºä¸“å®¶ {expert_folder.name} å¤±è´¥: {str(e)}")

    print(f"\nå…±åˆ›å»º {len(agents)} ä¸ªä¸“å®¶")
    print("ä¸“å®¶åˆ›å»ºå®Œæˆ\n")
    return agents


def get_expert_names(page_mode: str) -> list:
    """è·å–æ‰€æœ‰ä¸“å®¶åç§°

    Args:
        page_mode: é¡µé¢æ¨¡å¼ ('kol' æˆ–å…¶ä»–)
    """
    # --- ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨å‚³å…¥çš„ page_mode ---
    print(f"--- get_expert_names: ä½¿ç”¨é é¢æ¨¡å¼ {page_mode} ---")
    # --- ä¿®æ”¹çµæŸ ---
    data_dir = Path("data_kol") if page_mode == "kol" else Path("data") # <-- ä½¿ç”¨ page_mode
    return [folder.name for folder in data_dir.iterdir() if folder.is_dir()]


def create_summary_agent(model_type: str) -> Agent:
    """åˆ›å»ºæ€»ç»“ Agent"""
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ€»ç»“ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åˆ†æå’Œæ€»ç»“å…¶ä»–ä¸“å®¶çš„å›ç­”
2. æå–æ¯ä¸ªä¸“å®¶è§‚ç‚¹çš„æ ¸å¿ƒå†…å®¹
3. æ‰¾å‡ºä¸“å®¶ä»¬è§‚ç‚¹çš„å…±åŒç‚¹å’Œå·®å¼‚ç‚¹
4. ç»™å‡ºä¸€ä¸ªå…¨é¢çš„æ€»ç»“

è¯·ä»¥ä¸‹é¢çš„æ ¼å¼è¾“å‡ºï¼š
ğŸ“ æ ¸å¿ƒè§‚ç‚¹æ€»ç»“ï¼š
[æ€»ç»“å„ä¸ªä¸“å®¶çš„æ ¸å¿ƒè§‚ç‚¹]

ğŸ” å…±åŒç‚¹ï¼š
[åˆ—å‡ºä¸“å®¶ä»¬è§‚ç‚¹çš„å…±åŒä¹‹å¤„]

ğŸ’­ å·®å¼‚ç‚¹ï¼š
[åˆ—å‡ºä¸“å®¶ä»¬è§‚ç‚¹çš„ä¸»è¦å·®å¼‚]

ğŸ¯ ç»¼åˆå»ºè®®ï¼š
[åŸºäºæ‰€æœ‰ä¸“å®¶æ„è§ç»™å‡ºçš„ç»¼åˆå»ºè®®]
"""
    return Agent(
        model=create_model(model_type),
        system_prompt=system_prompt,
        markdown=True
    )


def get_summary_response(summary_agent: Agent, expert_responses: list) -> str:
    """è·å–æ€»ç»“ Agent çš„å“åº”"""
    # æ„å»ºè¾“å…¥ä¿¡æ¯
    summary_input = "è¯·æ€»ç»“ä»¥ä¸‹ä¸“å®¶çš„å›ç­”ï¼š\n\n"
    for response in expert_responses:
        summary_input += f"ã€{response['agent_name']
                             }ã€‘çš„è§‚ç‚¹ï¼š\n{response['content']}\n\n"

    # è·å–æ€»ç»“
    try:
        response = summary_agent.run(summary_input)
        return response.content
    except Exception as e:
        print(f"ç”Ÿæˆæ€»ç»“å¤±è´¥: {str(e)}")
        return "æŠ±æ­‰ï¼Œç”Ÿæˆæ€»ç»“æ—¶é‡åˆ°äº†é—®é¢˜ã€‚"
