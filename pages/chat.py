import streamlit as st
from phi.model.google import GeminiOpenAIChat
from phi.model.deepseek import DeepSeekChat
from phi.agent import Agent
from itertools import cycle

# å®šä¹‰å¯ç”¨çš„æ¨¡å‹
MODELS = {
    "gemini-2.0-flash-thinking-exp-1219": "Gemini Flash Thinking",
    "gemini-2.0-flash-exp": "Gemini Flash",
    "gemini-exp-1206": "Gemini 1206",
    "deepseek": "DeepSeek"
}

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI Chat",
    page_icon="ğŸ’­",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []
if "chat_is_processing" not in st.session_state:
    st.session_state.chat_is_processing = False
if "chat_error_count" not in st.session_state:
    st.session_state.chat_error_count = 0
if "current_model" not in st.session_state:
    st.session_state.current_model = "gemini-2.0-flash-thinking-exp-1219"
if "chat_processing_status" not in st.session_state:
    st.session_state.chat_processing_status = {
        "is_processing": False,
        "current_message": None,
        "current_image": None,
        "response_started": False
    }

# API key è½®æ¢


def get_next_api_key():
    if "api_key_cycle" not in st.session_state:
        st.session_state.api_key_cycle = cycle(st.secrets["GOOGLE_API_KEYS"])
    return next(st.session_state.api_key_cycle)

# åˆ›å»ºagent


def create_chat_agent(model_type: str):
    if model_type.startswith("gemini"):
        model = GeminiOpenAIChat(
            id=model_type,
            api_key=get_next_api_key(),
        )
    elif model_type == "deepseek":
        model = DeepSeekChat(
            api_key=st.secrets["DEEPSEEK_API_KEY"],
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

    return Agent(
        model=model,
        system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸“ä¸šã€å‡†ç¡®ã€å‹å–„çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚",
        markdown=True
    )

# è·å–å“åº”


def get_chat_response(agent: Agent, message: str, image=None, max_retries: int = 3) -> str:
    for attempt in range(max_retries + 1):
        try:
            # æ›´æ–°API keyï¼ˆä»…å¯¹Geminiæ¨¡å‹ï¼‰
            if isinstance(agent.model, GeminiOpenAIChat):
                agent.model.api_key = get_next_api_key()
                print(f"ä½¿ç”¨ API Key: {agent.model.api_key[:10]}...")

            if image and isinstance(agent.model, GeminiOpenAIChat):
                response = agent.run(message, images=[image])
            else:
                response = agent.run(message)
            return response.content

        except Exception as e:
            error_str = str(e)
            print(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {error_str}")

            if "429" in error_str and "RESOURCE_EXHAUSTED" in error_str:
                print("æ£€æµ‹åˆ°é…é¢è¶…é™é”™è¯¯ï¼Œæ­£åœ¨åˆ‡æ¢åˆ°æ–°çš„ API Key...")
                if attempt < max_retries:
                    continue

            if attempt < max_retries:
                print("æ­£åœ¨é‡è¯•...")
                continue
            else:
                print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼ˆ{error_str}ï¼‰ã€‚è¯·ç¨åå†è¯•ã€‚"


# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")

    # æ¨¡å‹é€‰æ‹©
    selected_model = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        list(MODELS.keys()),
        format_func=lambda x: MODELS[x],
        index=list(MODELS.keys()).index(st.session_state.current_model)
    )

    # å¦‚æœæ¨¡å‹æ”¹å˜ï¼Œæ›´æ–°ä¼šè¯çŠ¶æ€
    if selected_model != st.session_state.current_model:
        st.session_state.current_model = selected_model
        st.session_state.chat_messages = []  # æ¸…ç©ºå¯¹è¯å†å²
        st.rerun()

    # æ¸…ç©ºå¯¹è¯
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", type="primary"):
        st.session_state.chat_messages = []
        st.rerun()

    # ç³»ç»ŸçŠ¶æ€
    st.markdown("---")
    st.markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
    st.info(f"""
    - æ¨¡å‹: {MODELS[st.session_state.current_model]}
    - æ¶ˆæ¯æ•°: {len(st.session_state.chat_messages)}
    - çŠ¶æ€: {'ğŸŸ¢ æ­£å¸¸' if not st.session_state.chat_error_count else 'ğŸ”´ å¼‚å¸¸'}
    """)

# é¡µé¢æ ‡é¢˜
st.title("ğŸ’­ AI Chat")

# å›¾ç‰‡ä¸Šä¼ ï¼ˆä»…å¯¹Geminiæ¨¡å‹æ˜¾ç¤ºï¼‰
uploaded_image = None
if st.session_state.current_model.startswith("gemini"):
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰", type=['png', 'jpg', 'jpeg'])
    if uploaded_file is not None:
        st.image(uploaded_file, caption="å·²ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
        uploaded_image = uploaded_file.getvalue()

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.chat_messages:
    with st.chat_message(message["role"], avatar="ğŸ§‘â€ğŸ’»" if message["role"] == "user" else "ğŸ¤–"):
        st.markdown(message["content"])
        if "has_image" in message and message["has_image"]:
            st.image(message["image"], caption="ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡",
                     use_container_width=True)

# ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

# å¤„ç†æ–°çš„ç”¨æˆ·è¾“å…¥
if user_input and not st.session_state.chat_processing_status["is_processing"]:
    # è®¾ç½®å¤„ç†çŠ¶æ€
    st.session_state.chat_processing_status = {
        "is_processing": True,
        "current_message": user_input,
        "current_image": uploaded_image,
        "response_started": False
    }

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯çŠ¶æ€
    message_data = {
        "role": "user",
        "content": user_input,
    }
    if uploaded_image:
        message_data["has_image"] = True
        message_data["image"] = uploaded_image
    st.session_state.chat_messages.append(message_data)

# å¦‚æœæ­£åœ¨å¤„ç†ä¸­
elif st.session_state.chat_processing_status["is_processing"]:
    # è·å–å½“å‰æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯
    user_input = st.session_state.chat_processing_status["current_message"]
    uploaded_image = st.session_state.chat_processing_status["current_image"]

    # å¦‚æœè¿˜æ²¡æœ‰å¼€å§‹ç”Ÿæˆå“åº”
    if not st.session_state.chat_processing_status["response_started"]:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            with st.status("ğŸ¤” æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
                try:
                    agent = create_chat_agent(st.session_state.current_model)
                    response = get_chat_response(
                        agent, user_input, uploaded_image)
                    st.markdown(response)
                    status.update(label="âœ… å›ç­”å®Œæˆ",
                                  state="complete", expanded=True)

                    # ä¿å­˜å“åº”åˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.chat_messages.append({
                        "role": "assistant",
                        "content": response
                    })

                    # æ ‡è®°å“åº”å·²å®Œæˆ
                    st.session_state.chat_processing_status["response_started"] = True

                except Exception as e:
                    error_msg = f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"
                    st.error(error_msg)
                    # ä¿å­˜é”™è¯¯æ¶ˆæ¯åˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.chat_messages.append({
                        "role": "assistant",
                        "content": f"âŒ {error_msg}"
                    })
                finally:
                    # é‡ç½®å¤„ç†çŠ¶æ€
                    st.session_state.chat_processing_status = {
                        "is_processing": False,
                        "current_message": None,
                        "current_image": None,
                        "response_started": False
                    }

# æ·»åŠ åº•éƒ¨è¾¹è·
st.markdown("<div style='margin-bottom: 100px'></div>", unsafe_allow_html=True)
