import streamlit as st
import fitz  # PyMuPDF
import io
import base64
import tempfile
import time
import os
import traceback
from PIL import Image
from google import genai
from google.genai import types
from itertools import cycle
import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
import math
import re
from streamlit_pdf_viewer import pdf_viewer
import threading
# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Document Reader & Analyzer",
    page_icon="ğŸ“š",
    layout="wide"
)

# åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯


def get_next_api_key():
    """è·å–ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
    if "api_key_cycle" not in st.session_state:
        st.session_state.api_key_cycle = cycle(st.secrets["GOOGLE_API_KEYS"])
    return next(st.session_state.api_key_cycle)


def init_gemini_client():
    return genai.Client(
        api_key=get_next_api_key(),
    )

# PDFè½¬å›¾ç‰‡å‡½æ•°


def convert_pdf_to_images(pdf_document):
    images = []
    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        # é™ä½åˆ†è¾¨ç‡ä»¥å‡å°æ–‡ä»¶å¤§å°
        pix = page.get_pixmap(matrix=fitz.Matrix(150/72, 150/72))  # é™è‡³150 DPI
        img_data = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        # è°ƒæ•´å›¾ç‰‡å¤§å°
        img = resize_image(img)
        images.append(img)
    return images

# è°ƒæ•´å›¾ç‰‡å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡APIé™åˆ¶


def resize_image(image, max_size=1024):
    """è°ƒæ•´å›¾ç‰‡å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡APIé™åˆ¶"""
    width, height = image.size
    if width > max_size or height > max_size:
        ratio = min(max_size/width, max_size/height)
        new_size = (int(width * ratio), int(height * ratio))
        return image.resize(new_size, Image.Resampling.LANCZOS)
    return image

# è¯»å–EPUBæ–‡ä»¶å¹¶æŒ‰ç« èŠ‚åˆ†å‰²


def read_epub_by_chapters(file_content):
    """è¯»å–EPUBæ–‡ä»¶å¹¶æŒ‰ç« èŠ‚åˆ†å‰²å†…å®¹"""
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.epub') as temp_file:
            temp_file.write(file_content)
            temp_file_path = temp_file.name

        try:
            # è¯»å–EPUBæ–‡ä»¶
            book = epub.read_epub(temp_file_path)

            # å­˜å‚¨ç« èŠ‚å†…å®¹
            chapters = []
            chapter_titles = []

            # éå†æ‰€æœ‰é¡¹ç›®ï¼Œæå–ç« èŠ‚å†…å®¹
            for item in book.get_items():
                if item.get_type() == ebooklib.ITEM_DOCUMENT:
                    # è§£æHTMLå†…å®¹
                    soup = BeautifulSoup(item.get_content(), 'html.parser')

                    # å°è¯•è·å–ç« èŠ‚æ ‡é¢˜
                    title = soup.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                    chapter_title = title.get_text(
                    ) if title else f"Chapter {len(chapters) + 1}"

                    # è·å–ç« èŠ‚æ–‡æœ¬å†…å®¹
                    text = soup.get_text()

                    # å¦‚æœç« èŠ‚å†…å®¹ä¸ä¸ºç©ºï¼Œåˆ™æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    if text.strip():
                        chapters.append(text)
                        chapter_titles.append(chapter_title)

            return chapters, chapter_titles
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_file_path)
            except:
                pass
    except Exception as e:
        st.error(f"è¯»å–EPUBæ–‡ä»¶å¤±è´¥: {str(e)}")
        return [], []

# è®¡ç®—æ–‡æœ¬å­—æ•°


def count_words(text):
    """è®¡ç®—æ–‡æœ¬ä¸­çš„å­—æ•°ï¼ˆä¸­æ–‡å­—ç¬¦ + è‹±æ–‡å•è¯ï¼‰"""
    # åŒ¹é…ä¸­æ–‡å­—ç¬¦
    chinese_characters = re.findall(r'[\u4e00-\u9fff]', text)
    # åŒ¹é…è‹±æ–‡å•è¯
    english_words = re.findall(r'\b[a-zA-Z]+\b', text)
    # è¿”å›ä¸­æ–‡å­—ç¬¦æ•° + è‹±æ–‡å•è¯æ•°
    return len(chinese_characters) + len(english_words)

# åˆ†ææ–‡æ¡£é¡µé¢å†…å®¹


def analyze_page_content(client, prompt, content, page_info, max_retries=3, timeout_seconds=30):

    # åˆ›å»ºä¸€ä¸ªç»“æœå®¹å™¨
    result = {"text": None, "error": None, "completed": False}

    def api_call():
        try:
            full_prompt = f"""{content}

{prompt}"""

            model = "gemini-2.0-flash-exp"
            contents = [
                types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=full_prompt)],
                ),
            ]

            response = client.models.generate_content(
                model=model,
                contents=contents,
            )

            result["text"] = response.candidates[0].content.parts[0].text
            result["completed"] = True
        except Exception as e:
            result["error"] = str(e)

    # å°è¯•å¤šæ¬¡è°ƒç”¨API
    for attempt in range(max_retries):
        # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œåˆ™åˆ‡æ¢APIå¯†é’¥
        if attempt > 0:
            client = genai.Client(api_key=get_next_api_key())
            st.warning(f"âš ï¸ åˆ†æè¶…æ—¶ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ {attempt+1} æ¬¡å°è¯•...", icon="ğŸ”„")

        # é‡ç½®ç»“æœ
        result = {"text": None, "error": None, "completed": False}

        # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
        api_thread = threading.Thread(target=api_call)
        api_thread.daemon = True
        api_thread.start()

        # ç­‰å¾…çº¿ç¨‹å®Œæˆæˆ–è¶…æ—¶
        start_time = time.time()
        while not result["completed"] and time.time() - start_time < timeout_seconds:
            time.sleep(0.5)  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡

            # å¦‚æœçº¿ç¨‹å·²ç»å®Œæˆï¼Œè¿”å›ç»“æœ
            if result["completed"]:
                return result["text"]

        # å¦‚æœå·²ç»å®Œæˆï¼Œè¿”å›ç»“æœ
        if result["completed"]:
            return result["text"]

        # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ä¸”è¶…æ—¶
        if attempt == max_retries - 1:
            if result["error"]:
                return f"Analysis error after {max_retries} attempts: {result['error']}"
            else:
                return f"Analysis timed out after {max_retries} attempts (each waiting {timeout_seconds} seconds)"

    # è¿™é‡Œä¸åº”è¯¥åˆ°è¾¾ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§
    return "Analysis failed with unknown error"

# åˆ†æå›¾ç‰‡å†…å®¹


def analyze_image_content(images, user_prompt, timeout_seconds=120):
    """ä½¿ç”¨å›¾ç‰‡åˆ†æPDFå†…å®¹"""
    # ç”¨äºå­˜å‚¨ä¸´æ—¶æ–‡ä»¶è·¯å¾„ä»¥ä¾¿æœ€åæ¸…ç†
    temp_file_paths = []

    try:
        start_time = time.time()
        # å…ˆæ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"å¼€å§‹å¤„ç†{len(images)}å¼ å›¾ç‰‡çš„åˆ†æè¯·æ±‚...")

        if len(images) > 3:
            print(f"è­¦å‘Š: å°è¯•åŒæ—¶åˆ†æ{len(images)}å¼ å›¾ç‰‡ï¼Œå¯èƒ½å¯¼è‡´è¶…æ—¶")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = genai.Client(
            api_key=get_next_api_key(),
        )

        # åˆ›å»ºä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
        uploaded_files = []

        for i, img in enumerate(images):
            # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥æé«˜å¤„ç†é€Ÿåº¦
            img = resize_image(img, max_size=800)

            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
                temp_path = tmp_file.name
                temp_file_paths.append(temp_path)  # è®°å½•ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                img.save(temp_path, 'JPEG', optimize=True, quality=85)
                print(f"ä¿å­˜ä¸´æ—¶å›¾ç‰‡ {i+1}/{len(images)}: {temp_path}")

                # ä¸Šä¼ æ–‡ä»¶
                try:
                    # ä½¿ç”¨æ–°çš„APIæ ¼å¼ä¸Šä¼ æ–‡ä»¶
                    uploaded_file = client.files.upload(file=temp_path)
                    uploaded_files.append(uploaded_file)
                    print(f"æˆåŠŸä¸Šä¼ å›¾ç‰‡ {i+1} (ID: {uploaded_file.name})")
                except Exception as upload_err:
                    print(f"å›¾ç‰‡ {i+1} ä¸Šä¼ å¤±è´¥: {str(upload_err)}")
                    traceback.print_exc()
                    continue

        if not uploaded_files:
            return "æ‰€æœ‰å›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼Œæ— æ³•åˆ†æå†…å®¹ã€‚è¯·å°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ã€‚"

        # ä½¿ç”¨Geminiæ¨¡å‹è¿›è¡Œåˆ†æ
        model = "gemini-2.0-flash"  # ä½¿ç”¨æœ€æ–°æ¨èçš„æ¨¡å‹

        # æ„å»ºè¯·æ±‚å†…å®¹
        parts = []

        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        for file in uploaded_files:
            parts.append(
                types.Part.from_uri(
                    file_uri=file.uri,
                    mime_type=file.mime_type,
                )
            )

        # æ·»åŠ ç”¨æˆ·æç¤ºæ–‡æœ¬
        parts.append(types.Part.from_text(
            text=f"è¯·åˆ†æä»¥ä¸‹PDFé¡µé¢å›¾ç‰‡å†…å®¹ã€‚{user_prompt}"))

        contents = [
            types.Content(
                role="user",
                parts=parts,
            )
        ]

        # æ„å»ºç”Ÿæˆé…ç½®
        generate_content_config = types.GenerateContentConfig(
            temperature=0.2,
            top_p=0.95,
            top_k=40,
            max_output_tokens=8192,
            response_mime_type="text/plain",
        )

        # è°ƒç”¨APIç”Ÿæˆå†…å®¹
        response = client.models.generate_content(
            model=model,
            contents=contents,
            config=generate_content_config,
        )

        # è·å–ç»“æœæ–‡æœ¬
        result_text = response.candidates[0].content.parts[0].text if response.candidates else "æ— æ³•ç”Ÿæˆåˆ†æç»“æœ"

        end_time = time.time()
        print(f"å›¾ç‰‡åˆ†æå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")

        return result_text

    except Exception as e:
        error_msg = f"å›¾ç‰‡åˆ†æå‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        traceback.print_exc()
        return f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ã€‚è¯¦æƒ…: {error_msg}ã€‚\nè¯·å°è¯•å‡å°‘é¡µæ•°æˆ–åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼ã€‚"
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_path in temp_file_paths:
            try:
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    print(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            except Exception as e:
                print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")


# Main page
st.title("ğŸ“š Document Analyzer")

# åˆå§‹åŒ–session state
if 'current_chapter' not in st.session_state:
    st.session_state.current_chapter = 0
    print(f"åˆå§‹åŒ– current_chapter: {st.session_state.current_chapter}")
if 'document_type' not in st.session_state:
    st.session_state.document_type = None
if 'epub_chapters' not in st.session_state:
    st.session_state.epub_chapters = []
if 'epub_chapter_titles' not in st.session_state:
    st.session_state.epub_chapter_titles = []
if 'pdf_images' not in st.session_state:
    st.session_state.pdf_images = []
if 'pdf_analysis_mode' not in st.session_state:
    st.session_state.pdf_analysis_mode = "text"  # é»˜è®¤ä¸ºæ–‡æœ¬æ¨¡å¼

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader(
    "Upload Document (PDF/EPUB)", type=["pdf", "epub"])

# æ·»åŠ ä¸€ä¸ªæ ‡è®°æ¥è·Ÿè¸ªæ–‡ä»¶æ˜¯å¦å·²ç»å¤„ç†è¿‡
if 'file_processed' not in st.session_state:
    st.session_state.file_processed = False
    print('file_processed', st.session_state.file_processed)

# åªæœ‰å½“æ–‡ä»¶ä¸Šä¼ ä¸”æœªå¤„ç†è¿‡ï¼Œæˆ–è€…æ–‡ä»¶å‘ç”Ÿå˜åŒ–æ—¶æ‰å¤„ç†æ–‡ä»¶
if uploaded_file is not None:
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å‘ç”Ÿå˜åŒ–
    current_file_name = uploaded_file.name
    print('current_file_name', current_file_name)
    print('====')
    print("'last_file_name' not in st.session_state",
          'last_file_name' not in st.session_state)
    if 'last_file_name' not in st.session_state or st.session_state.last_file_name != current_file_name:
        st.session_state.last_file_name = current_file_name
        print('last_file_name', st.session_state.last_file_name)
        st.session_state.file_processed = False
        print('in uploaded_file file_processed',
              st.session_state.file_processed)

    if not st.session_state.file_processed:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            st.session_state.document_type = "pdf"
            # é‡ç½®EPUBç›¸å…³çŠ¶æ€
            st.session_state.epub_chapters = []
            st.session_state.epub_chapter_titles = []
            st.session_state.epub_pages = []
            st.session_state.current_chapter = 0
            st.session_state.current_page = 0

            # è¯»å–PDFæ–‡ä»¶å¹¶ä¿å­˜åˆ°session_stateä¸­ï¼Œé¿å…é‡å¤è¯»å–
            pdf_bytes = uploaded_file.read()
            st.session_state.pdf_bytes = pdf_bytes  # ä¿å­˜åŸå§‹å­—èŠ‚æ•°æ®

            # æ‰“å¼€PDFæ–‡æ¡£
            pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
            st.session_state.pdf_document_info = {
                'page_count': pdf_document.page_count,
                'title': pdf_document.metadata.get('title', 'æœªå‘½åæ–‡æ¡£')
            }

            # è½¬æ¢å¹¶ä¿å­˜å›¾ç‰‡
            st.session_state.pdf_images = convert_pdf_to_images(pdf_document)
            print(f"å·²è½¬æ¢ {len(st.session_state.pdf_images)} é¡µ PDF ä¸ºå›¾ç‰‡")

        elif file_extension == "epub":
            st.session_state.document_type = "epub"
            # è¯»å–EPUBæ–‡ä»¶
            epub_content = uploaded_file.read()
            st.session_state.epub_chapters, st.session_state.epub_chapter_titles = read_epub_by_chapters(
                epub_content)

            # è®¾ç½®åˆå§‹ç« èŠ‚
            if st.session_state.epub_chapters:
                st.session_state.current_chapter = 0
                print(
                    f"ä¸Šä¼ EPUBæ–‡ä»¶åè®¾ç½® current_chapter: {st.session_state.current_chapter}")

        # æ ‡è®°æ–‡ä»¶å·²å¤„ç†
        st.session_state.file_processed = True
        print('file_processed', st.session_state.file_processed)

# åœ¨ä¾§è¾¹æ æ·»åŠ æç¤ºè¯è¾“å…¥å’Œæ–‡æ¡£é¢„è§ˆ
with st.sidebar:
    st.subheader("ğŸ’­ Analysis Prompt")
    user_prompt = st.text_area(
        "Enter analysis prompt",
        height=150,
        placeholder="Example: Summarize the main content of this page..."
    )

    # ä¸ºPDFæ–‡ä»¶æ·»åŠ åˆ†ææ¨¡å¼åˆ‡æ¢
    if st.session_state.document_type == "pdf":
        st.subheader("ğŸ“„ PDF Analysis Mode")
        pdf_mode = st.toggle(
            "ä½¿ç”¨å›¾ç‰‡æ¨¡å¼åˆ†æ",
            value=st.session_state.pdf_analysis_mode == "image",
            help="å¼€å¯åå°†ä½¿ç”¨å›¾ç‰‡æ¨¡å¼åˆ†æPDFï¼Œå…³é—­åˆ™ä½¿ç”¨æ–‡æœ¬æ¨¡å¼"
        )
        st.session_state.pdf_analysis_mode = "image" if pdf_mode else "text"
        mode_description = "å½“å‰æ¨¡å¼ï¼š" + ("å›¾ç‰‡æ¨¡å¼ ğŸ–¼ï¸" if pdf_mode else "æ–‡æœ¬æ¨¡å¼ ğŸ“")
        st.write(mode_description)

        # å¦‚æœæ˜¯å›¾ç‰‡æ¨¡å¼ï¼Œæ·»åŠ å»ºè®®æ€§æç¤º
        if pdf_mode:
            # åœ¨å›¾ç‰‡æ¨¡å¼ä¸‹è°ƒæ•´æ‰¹æ¬¡å¤§å°çš„é»˜è®¤å€¼
            pages_per_batch = st.number_input(
                "æ¯æ‰¹åˆ†æé¡µæ•° (å¼ºçƒˆå»ºè®®æ¯æ‰¹1é¡µ)",
                min_value=1,
                max_value=3,  # é™åˆ¶æœ€å¤§é¡µæ•°
                value=1,
                help="å›¾ç‰‡æ¨¡å¼ä¸‹å¼ºçƒˆå»ºè®®æ¯æ‰¹åˆ†æ1é¡µä»¥æé«˜æˆåŠŸç‡"
            )
        else:
            # æ–‡æœ¬æ¨¡å¼ä¸‹çš„æ‰¹æ¬¡å¤§å°è®¾ç½®
            pages_per_batch = st.number_input(
                "Pages per analysis batch",
                min_value=1,
                max_value=100,
                value=5,
                help="Select how many pages to analyze together. Higher values mean fewer API calls but may affect analysis quality."
            )
    else:
        # éPDFæ–‡ä»¶çš„æ‰¹æ¬¡å¤§å°è®¾ç½®
        pages_per_batch = st.number_input(
            "Pages per analysis batch",
            min_value=1,
            max_value=100,
            value=5,
            help="Select how many pages to analyze together. Higher values mean fewer API calls but may affect analysis quality."
        )

    # æ·»åŠ ä¸€ä¸ªç¾è§‚çš„EnteræŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
        if not user_prompt:
            st.error("è¯·å…ˆè¾“å…¥åˆ†ææç¤ºï¼")
        else:
            if st.session_state.document_type == "pdf" and st.session_state.pdf_bytes:
                # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦
                progress_bar = st.progress(0)
                status_text = st.empty()

                # è®¡ç®—æ‰¹æ¬¡æ€»æ•°
                pdf_document = fitz.open(
                    stream=st.session_state.pdf_bytes, filetype="pdf")
                total_pages = pdf_document.page_count
                total_batches = (
                    total_pages + pages_per_batch - 1) // pages_per_batch

                combined_analysis = []

                # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
                for batch_idx in range(total_batches):
                    start_page = batch_idx * pages_per_batch
                    end_page = min((batch_idx + 1) *
                                   pages_per_batch, total_pages)

                    # æ›´æ–°è¿›åº¦æ¡
                    progress = (batch_idx) / total_batches
                    progress_bar.progress(progress)
                    status_text.info(
                        f"æ­£åœ¨å¤„ç†ç¬¬ {start_page + 1}-{end_page} é¡µ (æ‰¹æ¬¡ {batch_idx + 1}/{total_batches})")

                    # æ ¹æ®åˆ†ææ¨¡å¼é€‰æ‹©å¤„ç†æ–¹æ³•
                    if st.session_state.pdf_analysis_mode == "image" and 'pdf_images' in st.session_state:
                        # å›¾ç‰‡æ¨¡å¼åˆ†æ
                        with st.spinner(f"ğŸ–¼ï¸ æ­£åœ¨ä½¿ç”¨å›¾ç‰‡æ¨¡å¼åˆ†æç¬¬ {start_page + 1} åˆ° {end_page} é¡µ..."):
                            st.info("å›¾ç‰‡åˆ†æä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...")

                            # æ˜¾ç¤ºæ­£åœ¨åˆ†æçš„å›¾ç‰‡
                            cols = st.columns(min(3, end_page - start_page))
                            for i, col in enumerate(cols):
                                if start_page + i < len(st.session_state.pdf_images):
                                    with col:
                                        st.image(st.session_state.pdf_images[start_page + i],
                                                 caption=f"Page {start_page + i + 1}",
                                                 use_column_width=True)

                            # ç”Ÿæˆå›¾ç‰‡åˆ†æçš„æç¤ºè¯
                            image_prompt = f"{user_prompt}\n\nè¯·åˆ†æè¿™{'äº›' if end_page-start_page > 1 else ''}PDFé¡µé¢çš„å†…å®¹ã€‚"

                            try:
                                # åˆ†æå›¾ç‰‡å†…å®¹
                                analysis = analyze_image_content(
                                    st.session_state.pdf_images[start_page:end_page],
                                    image_prompt
                                )

                                # æ·»åŠ åˆ°åˆå¹¶ç»“æœ
                                batch_result = f"### ğŸ“„ ç¬¬ {start_page + 1}-{end_page} é¡µåˆ†æç»“æœ\n\n{analysis}"
                                combined_analysis.append(batch_result)

                            except Exception as e:
                                error_msg = f"å›¾ç‰‡åˆ†æå‡ºé”™: {str(e)}"
                                st.error(error_msg)
                                traceback.print_exc()

                                # å¦‚æœå›¾ç‰‡åˆ†æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ä½œä¸ºå¤‡é€‰
                                st.warning("å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œæ­£åœ¨å°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ä½œä¸ºå¤‡é€‰...")

                                # æå–å½“å‰æ‰¹æ¬¡çš„æ–‡æœ¬å†…å®¹
                                batch_text = ""
                                for page_num in range(start_page, end_page):
                                    if page_num < pdf_document.page_count:
                                        page = pdf_document[page_num]
                                        batch_text += page.get_text() + "\n\n"

                                # ä½¿ç”¨æ–‡æœ¬æ¨¡å¼è¿›è¡Œåˆ†æ
                                backup_analysis = analyze_page_content(
                                    init_gemini_client(),
                                    user_prompt,
                                    batch_text,
                                    f"PDF Pages {start_page + 1}-{end_page}"
                                )

                                batch_result = f"### ğŸ“„ ç¬¬ {start_page + 1}-{end_page} é¡µåˆ†æç»“æœ (æ–‡æœ¬æ¨¡å¼å¤‡é€‰)\n\n{backup_analysis}"
                                combined_analysis.append(batch_result)

                    else:
                        # æ–‡æœ¬æ¨¡å¼åˆ†æ
                        with st.spinner(f"ğŸ“ æ­£åœ¨ä½¿ç”¨æ–‡æœ¬æ¨¡å¼åˆ†æç¬¬ {start_page + 1} åˆ° {end_page} é¡µ..."):
                            # æå–å½“å‰æ‰¹æ¬¡çš„æ–‡æœ¬
                            batch_text = ""
                            for page_num in range(start_page, end_page):
                                if page_num < pdf_document.page_count:
                                    page = pdf_document[page_num]
                                    batch_text += page.get_text() + "\n\n"

                            # ä½¿ç”¨æ–‡æœ¬æ¨¡å¼è¿›è¡Œåˆ†æ
                            analysis = analyze_page_content(
                                init_gemini_client(),
                                user_prompt,
                                batch_text,
                                f"PDF Pages {start_page + 1}-{end_page}"
                            )

                            # æ·»åŠ åˆ°åˆå¹¶ç»“æœ
                            batch_result = f"### ğŸ“„ ç¬¬ {start_page + 1}-{end_page} é¡µåˆ†æç»“æœ\n\n{analysis}"
                            combined_analysis.append(batch_result)

                # å®Œæˆæ‰€æœ‰æ‰¹æ¬¡ï¼Œæ˜¾ç¤ºç»“æœ
                progress_bar.progress(1.0)
                status_text.success("âœ… åˆ†æå®Œæˆ!")

                # æ˜¾ç¤ºæ‰€æœ‰æ‰¹æ¬¡çš„åˆå¹¶ç»“æœ
                st.markdown("## ğŸ“Š åˆ†æç»“æœ")
                for result in combined_analysis:
                    st.markdown(result)
                    st.divider()

    # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ–‡æ¡£é¢„è§ˆ
    if uploaded_file is not None:
        try:
            if st.session_state.document_type == "pdf":
                # ä½¿ç”¨å·²ä¿å­˜çš„PDFæ•°æ®æ¥é¢„è§ˆ
                if 'pdf_bytes' in st.session_state:
                    pdf_viewer(st.session_state.pdf_bytes)

                    # å¦‚æœæ˜¯å›¾ç‰‡æ¨¡å¼ï¼Œæ˜¾ç¤ºå›¾ç‰‡ç¼©ç•¥å›¾é€‰æ‹©å™¨
                    if st.session_state.pdf_analysis_mode == "image" and 'pdf_images' in st.session_state:
                        st.subheader("ğŸ–¼ï¸ PDFå›¾ç‰‡é¢„è§ˆ")
                        # è·å–é¡µé¢æ€»æ•°
                        total_pages = len(st.session_state.pdf_images)
                        if total_pages > 0:
                            # æ·»åŠ é¡µé¢é€‰æ‹©å™¨
                            selected_page = st.slider(
                                "é€‰æ‹©é¡µé¢", 1, total_pages, 1)
                            # æ˜¾ç¤ºæ‰€é€‰é¡µé¢çš„ç¼©ç•¥å›¾
                            if selected_page <= len(st.session_state.pdf_images):
                                st.image(st.session_state.pdf_images[selected_page-1],
                                         caption=f"ç¬¬ {selected_page} é¡µ",
                                         use_column_width=True)
            elif st.session_state.document_type == "epub" and st.session_state.epub_chapters:
                # æ˜¾ç¤ºEPUBç« èŠ‚å¯¼èˆªå’Œå­—æ•°ç»Ÿè®¡
                st.subheader("ğŸ“‘ Chapters")
                for i, (title, content) in enumerate(zip(st.session_state.epub_chapter_titles, st.session_state.epub_chapters)):
                    word_count = count_words(content)
                    if st.button(f"{title} ({word_count} å­—)", key=f"chapter_{i}", use_container_width=True):
                        st.session_state.current_chapter = i
                        print(
                            f"ç‚¹å‡»ç« èŠ‚æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()

        except Exception as e:
            st.error(f'Error displaying document: {str(e)}')

# ä¸»å†…å®¹åŒºåŸŸ
if uploaded_file is not None:
    try:
        if st.session_state.document_type == "pdf":
            # ä½¿ç”¨å·²ä¿å­˜çš„PDFä¿¡æ¯ï¼Œé¿å…é‡å¤è¯»å–æ–‡ä»¶
            page_count = st.session_state.pdf_document_info['page_count']
            doc_title = st.session_state.pdf_document_info['title']

            # æ˜¾ç¤ºPDFä¿¡æ¯
            st.subheader(f"ğŸ“„ PDFæ–‡æ¡£ - {doc_title} ({page_count} é¡µ)")

            # è·å–å½“å‰é¡µé¢çš„æ–‡æœ¬å†…å®¹ç”¨äºåˆ†æ
            if user_prompt:
                with st.spinner('åˆ†æé¡µé¢å†…å®¹ä¸­...'):
                    client = init_gemini_client()

                    # æ˜¾ç¤ºåˆ†æç»“æœ
                    st.subheader('ğŸ“ åˆ†æç»“æœ')

                    # è®¡ç®—éœ€è¦å¤„ç†çš„æ‰¹æ¬¡æ•°
                    total_pages = page_count
                    batch_count = (
                        total_pages + pages_per_batch - 1) // pages_per_batch

                    # åˆ†æå¤„ç†çš„å…·ä½“é€»è¾‘
                    for batch in range(batch_count):
                        start_page = batch * pages_per_batch
                        end_page = min(
                            start_page + pages_per_batch, total_pages)

                        with st.spinner(f'ğŸ“š æ­£åœ¨åˆ†æç¬¬ {start_page + 1} åˆ° {end_page} é¡µ...'):
                            # æ ¹æ®åˆ†ææ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
                            if st.session_state.pdf_analysis_mode == "text":
                                # æ–‡æœ¬æ¨¡å¼ï¼šä½¿ç”¨é¢„å…ˆå­˜å‚¨çš„PDFå­—èŠ‚é‡æ–°æ‰“å¼€æ–‡æ¡£ä»¥æå–æ–‡æœ¬
                                batch_text = ""
                                # é‡æ–°æ‰“å¼€PDFä»¥è·å–æ–‡æœ¬ï¼ˆè¿™æ ·å¯ä»¥ç¡®ä¿æ¯æ¬¡éƒ½èƒ½æ­£ç¡®è·å–ï¼‰
                                with fitz.open(stream=st.session_state.pdf_bytes, filetype="pdf") as pdf_doc:
                                    for page_num in range(start_page, end_page):
                                        batch_text += pdf_doc[page_num].get_text() + \
                                            "\n\n"

                                # åˆ†æåˆå¹¶åçš„æ–‡æœ¬å†…å®¹
                                analysis = analyze_page_content(
                                    client, user_prompt, batch_text, f"PDF Pages {start_page + 1}-{end_page}")
                            else:
                                # å›¾ç‰‡æ¨¡å¼ï¼šåˆ†ææ¯ä¸ªé¡µé¢çš„å›¾ç‰‡
                                # æ˜¾ç¤ºæ­£åœ¨å¤„ç†çš„å›¾ç‰‡
                                st.subheader(
                                    f"æ­£åœ¨åˆ†æç¬¬ {start_page + 1} åˆ° {end_page} é¡µçš„å›¾ç‰‡")

                                # åœ¨åˆ†æå‰å±•ç¤ºè¦åˆ†æçš„é¡µé¢å›¾ç‰‡
                                img_cols = st.columns(
                                    min(3, end_page - start_page + 1))
                                for i, page_idx in enumerate(range(start_page, end_page)):
                                    if page_idx < len(st.session_state.pdf_images):
                                        with img_cols[i % len(img_cols)]:
                                            st.image(st.session_state.pdf_images[page_idx],
                                                     caption=f"ç¬¬ {page_idx + 1} é¡µ",
                                                     use_column_width=True)

                                # åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰æç¤ºè¯æ ¼å¼
                                image_prompt = f"ä»¥ä¸‹æ˜¯PDFçš„ç¬¬{start_page + 1}é¡µåˆ°ç¬¬{end_page}é¡µçš„å›¾ç‰‡ã€‚\n\n{user_prompt}"

                                # å…è®¸ç”¨æˆ·åœ¨åˆ†æå‰æŸ¥çœ‹å’Œç¡®è®¤å›¾ç‰‡
                                st.info("æ­£åœ¨ä½¿ç”¨å›¾ç‰‡æ¨¡å¼åˆ†æè¿™äº›é¡µé¢ã€‚å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")

                                # åˆ†æå›¾ç‰‡å†…å®¹
                                analysis = analyze_image_content(
                                    st.session_state.pdf_images[start_page:end_page],
                                    image_prompt
                                )

                                # å¦‚æœåˆ†æå¤±è´¥ï¼Œå¯ä»¥é€‰æ‹©åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼
                                if "å›¾ç‰‡åˆ†æé”™è¯¯" in analysis or "å›¾ç‰‡åˆ†æè¶…æ—¶" in analysis:
                                    st.error("å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œæ­£åœ¨å°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ä½œä¸ºå¤‡é€‰...")
                                    # å°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ä½œä¸ºå¤‡é€‰
                                    try:
                                        with fitz.open(stream=st.session_state.pdf_bytes, filetype="pdf") as pdf_doc:
                                            backup_text = ""
                                            for page_num in range(start_page, end_page):
                                                backup_text += pdf_doc[page_num].get_text(
                                                ) + "\n\n"

                                        backup_analysis = analyze_page_content(
                                            client, user_prompt, backup_text, f"PDF Pages {start_page + 1}-{end_page}")

                                        # ç»„åˆç»“æœ
                                        analysis += "\n\n---\n\n**æ–‡æœ¬æ¨¡å¼å¤‡é€‰åˆ†æç»“æœï¼š**\n" + backup_analysis
                                    except Exception as e:
                                        st.error(f"å¤‡é€‰æ–‡æœ¬åˆ†æä¹Ÿå¤±è´¥äº†: {str(e)}")

                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            if start_page + 1 == end_page:
                                st.success(
                                    f"ç¬¬ {start_page + 1} é¡µåˆ†æ", icon="ğŸ“š")
                            else:
                                st.success(
                                    f"ç¬¬ {start_page + 1} åˆ° {end_page} é¡µåˆ†æ", icon="ğŸ“š")
                            st.markdown(analysis)
                            st.markdown("---")  # Add separator

        elif st.session_state.document_type == "epub" and st.session_state.epub_chapters:
            # æ˜¾ç¤ºEPUBä¿¡æ¯
            total_chapters = len(st.session_state.epub_chapters)
            current_chapter = st.session_state.current_chapter
            current_chapter_title = st.session_state.epub_chapter_titles[current_chapter]
            current_content = st.session_state.epub_chapters[current_chapter]

            st.subheader(f"ğŸ“– {current_chapter_title}")
            st.caption(f"å­—æ•°ï¼š{count_words(current_content)}")

            # å¦‚æœæœ‰æç¤ºè¯ä¸”ç‚¹å‡»äº†EnteræŒ‰é’®ï¼Œæ‰æ˜¾ç¤ºåˆ†æç»“æœ
            if user_prompt and st.session_state.get("analyze_trigger", False):
                with st.spinner('Analyzing content...'):
                    client = init_gemini_client()

                    # æ˜¾ç¤ºåˆ†æç»“æœ
                    st.subheader('ğŸ“ Analysis Results')

                    # åˆ†æå½“å‰ç« èŠ‚å†…å®¹
                    with st.spinner(f'ğŸ“š Analyzing chapter {current_chapter + 1}...'):
                        analysis = analyze_page_content(
                            client, user_prompt, current_content, f"Chapter {current_chapter + 1}: {current_chapter_title}")
                        st.markdown(analysis)
                        st.markdown("---")  # Add separator
                # é‡ç½®åˆ†æè§¦å‘å™¨
                st.session_state.analyze_trigger = False

            # æ˜¾ç¤ºå½“å‰ç« èŠ‚å†…å®¹
            st.subheader("ğŸ“„ Chapter Content")
            st.markdown(current_content)
            st.markdown("---")

            # ç« èŠ‚å¯¼èˆªæŒ‰é’®
            col1, col2 = st.columns(2)
            with col1:
                if current_chapter > 0:
                    if st.button("â®ï¸ Previous Chapter"):
                        st.session_state.current_chapter -= 1
                        print(
                            f"ç‚¹å‡»ä¸Šä¸€ç« æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()
            with col2:
                if current_chapter < total_chapters - 1:
                    if st.button("â­ï¸ Next Chapter"):
                        st.session_state.current_chapter += 1
                        print(
                            f"ç‚¹å‡»ä¸‹ä¸€ç« æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()
    except Exception as e:
        st.error(f'Error processing document: {str(e)}')
