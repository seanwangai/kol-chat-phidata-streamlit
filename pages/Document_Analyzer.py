import streamlit as st
import fitz  # PyMuPDF
import io
import base64
import tempfile
import time
import os
import traceback
from PIL import Image
from google import genai
from google.genai import types
from itertools import cycle
import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
import math
import re
from streamlit_pdf_viewer import pdf_viewer
import threading
# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Document Reader & Analyzer",
    page_icon="ğŸ“š",
    layout="wide"
)

# åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
css = '''
<style>
    [data-testid="stSidebar"]{
        min-width: 400px;
        max-width: 1600px;
    }
</style>
'''
st.markdown(css, unsafe_allow_html=True)

def get_next_api_key():
    """è·å–ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
    if "api_key_cycle" not in st.session_state:
        st.session_state.api_key_cycle = cycle(st.secrets["GOOGLE_API_KEYS"])
    return next(st.session_state.api_key_cycle)


def init_gemini_client():
    return genai.Client(
        api_key=get_next_api_key(),
    )

# PDFè½¬å›¾ç‰‡å‡½æ•°


def convert_pdf_to_images(pdf_document):
    images = []
    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        # é™ä½åˆ†è¾¨ç‡ä»¥å‡å°æ–‡ä»¶å¤§å°
        pix = page.get_pixmap(matrix=fitz.Matrix(150/72, 150/72))  # é™è‡³150 DPI
        img_data = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        # è°ƒæ•´å›¾ç‰‡å¤§å°
        img = resize_image(img)
        images.append(img)
    return images

# è°ƒæ•´å›¾ç‰‡å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡APIé™åˆ¶


def resize_image(image, max_size=1024):
    """è°ƒæ•´å›¾ç‰‡å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡APIé™åˆ¶"""
    width, height = image.size
    if width > max_size or height > max_size:
        ratio = min(max_size/width, max_size/height)
        new_size = (int(width * ratio), int(height * ratio))
        return image.resize(new_size, Image.Resampling.LANCZOS)
    return image

# è¯»å–EPUBæ–‡ä»¶å¹¶æŒ‰ç« èŠ‚åˆ†å‰²


def read_epub_by_chapters(file_content):
    """è¯»å–EPUBæ–‡ä»¶å¹¶æŒ‰ç« èŠ‚åˆ†å‰²å†…å®¹"""
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.epub') as temp_file:
            temp_file.write(file_content)
            temp_file_path = temp_file.name

        try:
            # è¯»å–EPUBæ–‡ä»¶
            book = epub.read_epub(temp_file_path)

            # å­˜å‚¨ç« èŠ‚å†…å®¹
            chapters = []
            chapter_titles = []

            # éå†æ‰€æœ‰é¡¹ç›®ï¼Œæå–ç« èŠ‚å†…å®¹
            for item in book.get_items():
                if item.get_type() == ebooklib.ITEM_DOCUMENT:
                    # è§£æHTMLå†…å®¹
                    soup = BeautifulSoup(item.get_content(), 'html.parser')

                    # å°è¯•è·å–ç« èŠ‚æ ‡é¢˜
                    title = soup.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                    chapter_title = title.get_text(
                    ) if title else f"Chapter {len(chapters) + 1}"

                    # è·å–ç« èŠ‚æ–‡æœ¬å†…å®¹
                    text = soup.get_text()

                    # å¦‚æœç« èŠ‚å†…å®¹ä¸ä¸ºç©ºï¼Œåˆ™æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    if text.strip():
                        chapters.append(text)
                        chapter_titles.append(chapter_title)

            return chapters, chapter_titles
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_file_path)
            except:
                pass
    except Exception as e:
        st.error(f"è¯»å–EPUBæ–‡ä»¶å¤±è´¥: {str(e)}")
        return [], []

# è®¡ç®—æ–‡æœ¬å­—æ•°


def count_words(text):
    """è®¡ç®—æ–‡æœ¬ä¸­çš„å­—æ•°ï¼ˆä¸­æ–‡å­—ç¬¦ + è‹±æ–‡å•è¯ï¼‰"""
    # åŒ¹é…ä¸­æ–‡å­—ç¬¦
    chinese_characters = re.findall(r'[\u4e00-\u9fff]', text)
    # åŒ¹é…è‹±æ–‡å•è¯
    english_words = re.findall(r'\b[a-zA-Z]+\b', text)
    # è¿”å›ä¸­æ–‡å­—ç¬¦æ•° + è‹±æ–‡å•è¯æ•°
    return len(chinese_characters) + len(english_words)

# åˆ†ææ–‡æ¡£é¡µé¢å†…å®¹


def analyze_page_content(client, prompt, content, page_info, max_retries=3, timeout_seconds=30):

    # åˆ›å»ºä¸€ä¸ªç»“æœå®¹å™¨
    result = {"text": None, "error": None, "completed": False}

    def api_call():
        try:
            full_prompt = f"""{content}

{prompt}"""

            model = "gemini-2.0-flash-exp"
            contents = [
                types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=full_prompt)],
                ),
            ]

            response = client.models.generate_content(
                model=model,
                contents=contents,
            )

            result["text"] = response.candidates[0].content.parts[0].text
            result["completed"] = True
        except Exception as e:
            result["error"] = str(e)

    # å°è¯•å¤šæ¬¡è°ƒç”¨API
    for attempt in range(max_retries):
        # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œåˆ™åˆ‡æ¢APIå¯†é’¥
        if attempt > 0:
            client = genai.Client(api_key=get_next_api_key())
            st.warning(f"âš ï¸ åˆ†æè¶…æ—¶ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ {attempt+1} æ¬¡å°è¯•...", icon="ğŸ”„")

        # é‡ç½®ç»“æœ
        result = {"text": None, "error": None, "completed": False}

        # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
        api_thread = threading.Thread(target=api_call)
        api_thread.daemon = True
        api_thread.start()

        # ç­‰å¾…çº¿ç¨‹å®Œæˆæˆ–è¶…æ—¶
        start_time = time.time()
        while not result["completed"] and time.time() - start_time < timeout_seconds:
            time.sleep(0.5)  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡

            # å¦‚æœçº¿ç¨‹å·²ç»å®Œæˆï¼Œè¿”å›ç»“æœ
            if result["completed"]:
                return result["text"]

        # å¦‚æœå·²ç»å®Œæˆï¼Œè¿”å›ç»“æœ
        if result["completed"]:
            return result["text"]

        # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ä¸”è¶…æ—¶
        if attempt == max_retries - 1:
            if result["error"]:
                return f"Analysis error after {max_retries} attempts: {result['error']}"
            else:
                return f"Analysis timed out after {max_retries} attempts (each waiting {timeout_seconds} seconds)"

    # è¿™é‡Œä¸åº”è¯¥åˆ°è¾¾ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§
    return "Analysis failed with unknown error"

# åˆ†æå›¾ç‰‡å†…å®¹


def analyze_image_content(images, user_prompt, timeout_seconds=120):
    """ä½¿ç”¨å›¾ç‰‡åˆ†æPDFå†…å®¹"""
    # ç”¨äºå­˜å‚¨ä¸´æ—¶æ–‡ä»¶è·¯å¾„ä»¥ä¾¿æœ€åæ¸…ç†
    temp_file_paths = []

    try:
        start_time = time.time()
        # å…ˆæ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"å¼€å§‹å¤„ç†{len(images)}å¼ å›¾ç‰‡çš„åˆ†æè¯·æ±‚...")

        if len(images) > 10:
            print(f"è­¦å‘Š: å°è¯•åŒæ—¶åˆ†æ{len(images)}å¼ å›¾ç‰‡ï¼Œå¯èƒ½å¯¼è‡´è¶…æ—¶")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = genai.Client(
            api_key=get_next_api_key(),
        )

        # åˆ›å»ºä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
        uploaded_files = []
        print('====è™•ç†åœ–ç‰‡ä¸­===')
        for i, img in enumerate(images):
            # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥æé«˜å¤„ç†é€Ÿåº¦
            img = resize_image(img, max_size=800)

            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
                temp_path = tmp_file.name
                temp_file_paths.append(temp_path)  # è®°å½•ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                img.save(temp_path, 'JPEG', optimize=True, quality=85)
                print(f"ä¿å­˜ä¸´æ—¶å›¾ç‰‡ {i+1}/{len(images)}: {temp_path}")

                # ä¸Šä¼ æ–‡ä»¶
                try:
                    # ä½¿ç”¨æ–°çš„APIæ ¼å¼ä¸Šä¼ æ–‡ä»¶
                    uploaded_file = client.files.upload(file=temp_path)
                    uploaded_files.append(uploaded_file)
                    print(f"æˆåŠŸä¸Šä¼ å›¾ç‰‡ {i+1} (ID: {uploaded_file.name})")
                except Exception as upload_err:
                    print(f"å›¾ç‰‡ {i+1} ä¸Šä¼ å¤±è´¥: {str(upload_err)}")
                    traceback.print_exc()
                    continue

        if not uploaded_files:
            return "æ‰€æœ‰å›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼Œæ— æ³•åˆ†æå†…å®¹ã€‚è¯·å°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ã€‚"

        # ä½¿ç”¨Geminiæ¨¡å‹è¿›è¡Œåˆ†æ
        model = "gemini-2.0-flash"  # ä½¿ç”¨æœ€æ–°æ¨èçš„æ¨¡å‹

        # æ„å»ºè¯·æ±‚å†…å®¹
        parts = []

        print('====æ·»åŠ æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ä¸­===')
        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        for file in uploaded_files:
            parts.append(
                types.Part.from_uri(
                    file_uri=file.uri,
                    mime_type=file.mime_type,
                )
            )

        # æ·»åŠ ç”¨æˆ·æç¤ºæ–‡æœ¬
        parts.append(types.Part.from_text(
            text=f"è¯·åˆ†æä»¥ä¸‹PDFé¡µé¢å›¾ç‰‡å†…å®¹ã€‚{user_prompt}"))

        contents = [
            types.Content(
                role="user",
                parts=parts,
            )
        ]

        # æ„å»ºç”Ÿæˆé…ç½®
        generate_content_config = types.GenerateContentConfig(
            temperature=0.2,
            top_p=0.95,
            top_k=40,
            max_output_tokens=8192,
            response_mime_type="text/plain",
        )
        print('====è°ƒç”¨APIç”Ÿæˆå†…å®¹ä¸­===')
        # è°ƒç”¨APIç”Ÿæˆå†…å®¹
        response = client.models.generate_content(
            model=model,
            contents=contents,
            config=generate_content_config,
        )
        print('====è·å–ç»“æœæ–‡æœ¬ä¸­===')
        # è·å–ç»“æœæ–‡æœ¬
        result_text = response.candidates[0].content.parts[0].text if response.candidates else "æ— æ³•ç”Ÿæˆåˆ†æç»“æœ"

        end_time = time.time()
        print(f"å›¾ç‰‡åˆ†æå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")

        return result_text

    except Exception as e:
        error_msg = f"å›¾ç‰‡åˆ†æå‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        traceback.print_exc()
        return f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ã€‚è¯¦æƒ…: {error_msg}ã€‚\nè¯·å°è¯•å‡å°‘é¡µæ•°æˆ–åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼ã€‚"
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_path in temp_file_paths:
            try:
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    print(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            except Exception as e:
                print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")


# Main page
st.title("ğŸ“š Document Analyzer")

# åˆå§‹åŒ–session state
if 'current_chapter' not in st.session_state:
    st.session_state.current_chapter = 0
    print(f"åˆå§‹åŒ– current_chapter: {st.session_state.current_chapter}")
if 'document_type' not in st.session_state:
    st.session_state.document_type = None
if 'epub_chapters' not in st.session_state:
    st.session_state.epub_chapters = []
if 'epub_chapter_titles' not in st.session_state:
    st.session_state.epub_chapter_titles = []
if 'pdf_images' not in st.session_state:
    st.session_state.pdf_images = []
if 'pdf_analysis_mode' not in st.session_state:
    st.session_state.pdf_analysis_mode = "text"  # é»˜è®¤ä¸ºæ–‡æœ¬æ¨¡å¼

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader(
    "Upload Document (PDF/EPUB)", type=["pdf", "epub"])

# æ·»åŠ ä¸€ä¸ªæ ‡è®°æ¥è·Ÿè¸ªæ–‡ä»¶æ˜¯å¦å·²ç»å¤„ç†è¿‡
if 'file_processed' not in st.session_state:
    st.session_state.file_processed = False
    print('file_processed', st.session_state.file_processed)

# åªæœ‰å½“æ–‡ä»¶ä¸Šä¼ ä¸”æœªå¤„ç†è¿‡ï¼Œæˆ–è€…æ–‡ä»¶å‘ç”Ÿå˜åŒ–æ—¶æ‰å¤„ç†æ–‡ä»¶
if uploaded_file is not None:
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å‘ç”Ÿå˜åŒ–
    current_file_name = uploaded_file.name
    print('current_file_name', current_file_name)
    print('====')
    print("'last_file_name' not in st.session_state",
          'last_file_name' not in st.session_state)
    if 'last_file_name' not in st.session_state or st.session_state.last_file_name != current_file_name:
        st.session_state.last_file_name = current_file_name
        print('last_file_name', st.session_state.last_file_name)
        st.session_state.file_processed = False
        print('in uploaded_file file_processed',
              st.session_state.file_processed)

    if not st.session_state.file_processed:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            st.session_state.document_type = "pdf"
            # é‡ç½®EPUBç›¸å…³çŠ¶æ€
            st.session_state.epub_chapters = []
            st.session_state.epub_chapter_titles = []
            st.session_state.epub_pages = []
            st.session_state.current_chapter = 0
            st.session_state.current_page = 0

            # è¯»å–PDFæ–‡ä»¶å¹¶ä¿å­˜åˆ°session_stateä¸­ï¼Œé¿å…é‡å¤è¯»å–
            pdf_bytes = uploaded_file.read()
            st.session_state.pdf_bytes = pdf_bytes  # ä¿å­˜åŸå§‹å­—èŠ‚æ•°æ®

            # æ‰“å¼€PDFæ–‡æ¡£
            pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
            st.session_state.pdf_document_info = {
                'page_count': pdf_document.page_count,
                'title': pdf_document.metadata.get('title', 'æœªå‘½åæ–‡æ¡£')
            }

            # è½¬æ¢å¹¶ä¿å­˜å›¾ç‰‡
            st.session_state.pdf_images = convert_pdf_to_images(pdf_document)
            print(f"å·²è½¬æ¢ {len(st.session_state.pdf_images)} é¡µ PDF ä¸ºå›¾ç‰‡")

        elif file_extension == "epub":
            st.session_state.document_type = "epub"
            # è¯»å–EPUBæ–‡ä»¶
            epub_content = uploaded_file.read()
            st.session_state.epub_chapters, st.session_state.epub_chapter_titles = read_epub_by_chapters(
                epub_content)

            # è®¾ç½®åˆå§‹ç« èŠ‚
            if st.session_state.epub_chapters:
                st.session_state.current_chapter = 0
                print(
                    f"ä¸Šä¼ EPUBæ–‡ä»¶åè®¾ç½® current_chapter: {st.session_state.current_chapter}")

        # æ ‡è®°æ–‡ä»¶å·²å¤„ç†
        st.session_state.file_processed = True
        print('file_processed', st.session_state.file_processed)

# åœ¨ä¾§è¾¹æ æ·»åŠ æç¤ºè¯è¾“å…¥å’Œæ–‡æ¡£é¢„è§ˆ
with st.sidebar:
    st.subheader("ğŸ’­ Analysis Prompt")
    user_prompt = st.text_area(
        "Enter analysis prompt",
        height=150,
        placeholder="Example: Summarize the main content of this page..."
    )

    # --- ä¿®æ”¹ï¼šåªæœ‰éEPUBæ–‡ä»¶æ‰é¡¯ç¤º pages_per_batch --- 
    if st.session_state.get('document_type') != "epub":
        # ä¸ºPDFæ–‡ä»¶æ·»åŠ åˆ†ææ¨¡å¼åˆ‡æ¢
        if st.session_state.document_type == "pdf":
            st.subheader("ğŸ“„ PDF Analysis Mode")
            pdf_mode = st.toggle(
                "ä½¿ç”¨å›¾ç‰‡æ¨¡å¼åˆ†æ",
                value=st.session_state.pdf_analysis_mode == "image",
                help="å¼€å¯åå°†ä½¿ç”¨å›¾ç‰‡æ¨¡å¼åˆ†æPDFï¼Œå…³é—­åˆ™ä½¿ç”¨æ–‡æœ¬æ¨¡å¼"
            )
            st.session_state.pdf_analysis_mode = "image" if pdf_mode else "text"
            mode_description = "å½“å‰æ¨¡å¼ï¼š" + ("å›¾ç‰‡æ¨¡å¼ ğŸ–¼ï¸" if pdf_mode else "æ–‡æœ¬æ¨¡å¼ ğŸ“")
            st.write(mode_description)

            # å¦‚æœæ˜¯å›¾ç‰‡æ¨¡å¼ï¼Œæ·»åŠ å»ºè®®æ€§æç¤º
            if pdf_mode:
                # åœ¨å›¾ç‰‡æ¨¡å¼ä¸‹è°ƒæ•´æ‰¹æ¬¡å¤§å°çš„é»˜è®¤å€¼
                pages_per_batch = st.number_input(
                    "æ¯æ‰¹åˆ†æé¡µæ•°",
                    min_value=1,
                    max_value=10,  # é™åˆ¶æœ€å¤§é¡µæ•°
                    value=3,
                    help="å¯ä»¥ä¸€æ¬¡å¤šå¼µå›¾ç‰‡"
                )
            else:
                # æ–‡æœ¬æ¨¡å¼ä¸‹çš„æ‰¹æ¬¡å¤§å°è®¾ç½®
                pages_per_batch = st.number_input(
                    "Pages per analysis batch",
                    min_value=1,
                    max_value=100,
                    value=5,
                    help="Select how many pages to analyze together. Higher values mean fewer API calls but may affect analysis quality."
                )
        else:
            # éPDF/EPUBæ–‡ä»¶çš„æ‰¹æ¬¡å¤§å°è®¾ç½® (ç†è®ºä¸Šä¸ä¼šè¿›å…¥ï¼Œå› ä¸ºç±»å‹é™åˆ¶äº†PDF/EPUB)
            pages_per_batch = st.number_input(
                "Pages per analysis batch",
                min_value=1,
                max_value=100,
                value=5,
                help="Select how many pages to analyze together. Higher values mean fewer API calls but may affect analysis quality."
            )
    else:
        # å¦‚æœæ˜¯ EPUBï¼Œè®¾ç½®ä¸€ä¸ªé»˜è®¤å€¼æˆ–æ ‡è®°ï¼Œè™½ç„¶ä¸ä¼šè¢«ä½¿ç”¨
        pages_per_batch = 1 # æˆ– None
    # --- ä¿®æ”¹çµæŸ --- 

    # æ·»åŠ ä¸€ä¸ªç¾è§‚çš„EnteræŒ‰é’®
    analyze_button = st.button(
        "ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True)

    # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ–‡æ¡£é¢„è§ˆ
    if uploaded_file is not None:
        try:
            if st.session_state.document_type == "pdf":
                # ä½¿ç”¨å·²ä¿å­˜çš„PDFæ•°æ®æ¥é¢„è§ˆ
                if 'pdf_bytes' in st.session_state:
                    pdf_viewer(st.session_state.pdf_bytes)

                    # å¦‚æœæ˜¯å›¾ç‰‡æ¨¡å¼ï¼Œæ˜¾ç¤ºå›¾ç‰‡ç¼©ç•¥å›¾é€‰æ‹©å™¨
                    if st.session_state.pdf_analysis_mode == "image" and 'pdf_images' in st.session_state:
                        st.subheader("ğŸ–¼ï¸ PDFå›¾ç‰‡é¢„è§ˆ")
                        # è·å–é¡µé¢æ€»æ•°
                        total_pages = len(st.session_state.pdf_images)
                        if total_pages > 0:
                            # æ·»åŠ é¡µé¢é€‰æ‹©å™¨
                            selected_page = st.slider(
                                "é€‰æ‹©é¡µé¢", 1, total_pages, 1)
                            # æ˜¾ç¤ºæ‰€é€‰é¡µé¢çš„ç¼©ç•¥å›¾
                            if selected_page <= len(st.session_state.pdf_images):
                                st.image(st.session_state.pdf_images[selected_page-1],
                                         caption=f"ç¬¬ {selected_page} é¡µ",
                                         use_container_width=True)
            elif st.session_state.document_type == "epub" and st.session_state.epub_chapters:
                # æ˜¾ç¤ºEPUBç« èŠ‚å¯¼èˆªå’Œå­—æ•°ç»Ÿè®¡
                st.subheader("ğŸ“‘ Chapters")
                for i, (title, content) in enumerate(zip(st.session_state.epub_chapter_titles, st.session_state.epub_chapters)):
                    word_count = count_words(content)
                    if st.button(f"{title} ({word_count} å­—)", key=f"chapter_{i}", use_container_width=True):
                        st.session_state.current_chapter = i
                        print(
                            f"ç‚¹å‡»ç« èŠ‚æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()

                # --- æ–°å¢ï¼šåœ¨å´é‚Šæ¬„åº•éƒ¨é¡¯ç¤ºç•¶å‰ç« ç¯€å…§å®¹ --- 
                st.divider()
                st.subheader("ğŸ“„ Current Chapter Content")
                current_chapter_idx = st.session_state.get('current_chapter', 0)
                if current_chapter_idx < len(st.session_state.epub_chapters):
                    sidebar_chapter_title = st.session_state.epub_chapter_titles[current_chapter_idx]
                    sidebar_chapter_content = st.session_state.epub_chapters[current_chapter_idx]
                    with st.expander(f"{sidebar_chapter_title}", expanded=False):
                        st.markdown(sidebar_chapter_content)
                # --- æ–°å¢çµæŸ ---

        except Exception as e:
            st.error(f'Error displaying document: {str(e)}')

# ä¸»å†…å®¹åŒºåŸŸ
if uploaded_file is not None:
    try:
        if st.session_state.document_type == "pdf":
            # --- PDF è™•ç†é‚è¼¯ (ä¿æŒä¸è®Š) --- 
            # ä½¿ç”¨å·²ä¿å­˜çš„PDFä¿¡æ¯ï¼Œé¿å…é‡å¤è¯»å–æ–‡ä»¶
            page_count = st.session_state.pdf_document_info['page_count']
            doc_title = st.session_state.pdf_document_info['title']

            # æ˜¾ç¤ºPDFä¿¡æ¯
            st.subheader(f"ğŸ“„ PDFæ–‡æ¡£ - {doc_title} ({page_count} é¡µ)")

            # åœ¨è¿™é‡Œæ˜¾ç¤ºPDFçš„é¢„è§ˆæˆ–å…¶ä»–ä¿¡æ¯ï¼Œä½†ä¸è‡ªåŠ¨æ‰§è¡Œåˆ†æ
            if not analyze_button:
                st.info("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥åˆ†ææç¤ºï¼Œç„¶åç‚¹å‡»ã€ŒğŸš€ å¼€å§‹åˆ†æã€æŒ‰é’®å¼€å§‹åˆ†æã€‚")

            # å¦‚æœç‚¹å‡»äº†åˆ†ææŒ‰é’®ï¼Œæ˜¾ç¤ºåˆ†æç»“æœ
            if analyze_button:
                if not user_prompt:
                    st.error("è¯·å…ˆè¾“å…¥åˆ†ææç¤ºï¼")
                else:
                    # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    # è®¡ç®—æ‰¹æ¬¡æ€»æ•°
                    pdf_document = fitz.open(
                        stream=st.session_state.pdf_bytes, filetype="pdf")
                    total_pages = pdf_document.page_count
                    total_batches = (
                        total_pages + pages_per_batch - 1) // pages_per_batch

                    combined_analysis = []

                    # åˆ›å»ºä¸€ä¸ªç©ºå®¹å™¨ç”¨äºæ˜¾ç¤ºå®æ—¶åˆ†æç»“æœ
                    analysis_container = st.empty()
                    
                    # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
                    for batch_idx in range(total_batches):
                        start_page = batch_idx * pages_per_batch
                        end_page = min((batch_idx + 1) * pages_per_batch, total_pages)
                    
                        # æ›´æ–°è¿›åº¦æ¡
                        progress = (batch_idx) / total_batches
                        progress_bar.progress(progress)
                        status_text.info(f"æ­£åœ¨å¤„ç†ç¬¬ {start_page + 1}-{end_page} é¡µ (æ‰¹æ¬¡ {batch_idx + 1}/{total_batches})")
                    
                        # æ ¹æ®åˆ†ææ¨¡å¼é€‰æ‹©å¤„ç†æ–¹æ³•
                        if st.session_state.pdf_analysis_mode == "image" and 'pdf_images' in st.session_state:
                            # å›¾ç‰‡æ¨¡å¼åˆ†æ
                            with st.spinner(f"ğŸ–¼ï¸ æ­£åœ¨ä½¿ç”¨å›¾ç‰‡æ¨¡å¼åˆ†æç¬¬ {start_page + 1} åˆ° {end_page} é¡µ..."):
                                # ç”Ÿæˆå›¾ç‰‡åˆ†æçš„æç¤ºè¯
                                image_prompt = f"{user_prompt}\n\nè¯·åˆ†æè¿™{{'äº›' if end_page-start_page > 1 else ''}}PDFé¡µé¢çš„å†…å®¹ã€‚"
                    
                                try:
                                    # åˆ†æå›¾ç‰‡å†…å®¹
                                    analysis = analyze_image_content(
                                        st.session_state.pdf_images[start_page:end_page],
                                        image_prompt
                                    )
                    
                                    # æ·»åŠ åˆ°åˆå¹¶ç»“æœ
                                    batch_result = f"### ğŸ“„ ç¬¬ {start_page + 1}-{end_page} é¡µåˆ†æç»“æœ\n\n{analysis}"
                                    combined_analysis.append(batch_result)
                    
                                    # å®æ—¶æ˜¾ç¤ºæ‰€æœ‰åˆ†æç»“æœ
                                    analysis_container.markdown("\n---\n".join(combined_analysis))
                    
                                except Exception as e:
                                    error_msg = f"å›¾ç‰‡åˆ†æå‡ºé”™: {str(e)}"
                                    st.error(error_msg)
                                    traceback.print_exc()
                    
                                    # å¦‚æœå›¾ç‰‡åˆ†æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ä½œä¸ºå¤‡é€‰
                                    st.warning("å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œæ­£åœ¨å°è¯•ä½¿ç”¨æ–‡æœ¬æ¨¡å¼ä½œä¸ºå¤‡é€‰...")
                    
                                    # æå–å½“å‰æ‰¹æ¬¡çš„æ–‡æœ¬å†…å®¹
                                    batch_text = ""
                                    for page_num in range(start_page, end_page):
                                        if page_num < pdf_document.page_count:
                                            page = pdf_document[page_num]
                                            batch_text += page.get_text() + "\n\n"
                    
                                    # ä½¿ç”¨æ–‡æœ¬æ¨¡å¼è¿›è¡Œåˆ†æ
                                    backup_analysis = analyze_page_content(
                                        init_gemini_client(),
                                        user_prompt,
                                        batch_text,
                                        f"PDF Pages {start_page + 1}-{end_page}"
                                    )
                    
                                    batch_result = f"### ğŸ“„ ç¬¬ {start_page + 1}-{end_page} é¡µåˆ†æç»“æœ (æ–‡æœ¬æ¨¡å¼å¤‡é€‰)\n\n{backup_analysis}"
                                    combined_analysis.append(batch_result)
                    
                                    # å®æ—¶æ˜¾ç¤ºæ‰€æœ‰åˆ†æç»“æœ
                                    analysis_container.markdown("\n---\n".join(combined_analysis))
                        else:
                            # æ–‡æœ¬æ¨¡å¼åˆ†æ
                            with st.spinner(f"ğŸ“ æ­£åœ¨ä½¿ç”¨æ–‡æœ¬æ¨¡å¼åˆ†æç¬¬ {start_page + 1} åˆ° {end_page} é¡µ..."):
                                # æå–å½“å‰æ‰¹æ¬¡çš„æ–‡æœ¬
                                batch_text = ""
                                for page_num in range(start_page, end_page):
                                    if page_num < pdf_document.page_count:
                                        page = pdf_document[page_num]
                                        batch_text += page.get_text() + "\n\n"

                                # ä½¿ç”¨æ–‡æœ¬æ¨¡å¼è¿›è¡Œåˆ†æ
                                analysis = analyze_page_content(
                                    init_gemini_client(),
                                    user_prompt,
                                    batch_text,
                                    f"PDF Pages {start_page + 1}-{end_page}"
                                )

                                # æ·»åŠ åˆ°åˆå¹¶ç»“æœ
                                batch_result = f"### ğŸ“„ ç¬¬ {start_page + 1}-{end_page} é¡µåˆ†æç»“æœ\n\n{analysis}"
                                combined_analysis.append(batch_result)

                                # å®æ—¶æ˜¾ç¤ºæ‰€æœ‰åˆ†æç»“æœ
                                analysis_container.markdown("\n---\n".join(combined_analysis))

                    # å®Œæˆæ‰€æœ‰æ‰¹æ¬¡ï¼Œæ˜¾ç¤ºç»“æœ
                    progress_bar.progress(1.0)
                    status_text.success("âœ… åˆ†æå®Œæˆ!")

                    # æ˜¾ç¤ºæ‰€æœ‰æ‰¹æ¬¡çš„åˆå¹¶ç»“æœ
                    st.markdown("## ğŸ“Š åˆ†æç»“æœ")
                    for result in combined_analysis:
                        st.markdown(result)
                        st.divider()
            # --- PDF è™•ç†é‚è¼¯çµæŸ --- 

        elif st.session_state.document_type == "epub" and st.session_state.epub_chapters:
            # --- EPUB è™•ç†é‚è¼¯é–‹å§‹ --- 
            total_chapters = len(st.session_state.epub_chapters)
            current_chapter = st.session_state.current_chapter
            current_chapter_title = st.session_state.epub_chapter_titles[current_chapter]
            current_content = st.session_state.epub_chapters[current_chapter]

            st.subheader(f"ğŸ“– {current_chapter_title}")
            st.caption(f"å­—æ•°ï¼š{count_words(current_content)}")

            # --- ä¿®æ”¹ï¼šè™•ç†é è¨­ prompt å’Œé¡¯ç¤ºé †åº --- 
            if analyze_button:
                # --- æ–°å¢ï¼šæª¢æŸ¥ user_prompt æ˜¯å¦ç‚ºç©ºï¼Œå¦‚æœç‚ºç©ºå‰‡ä½¿ç”¨é è¨­ prompt --- 
                if not user_prompt or user_prompt.strip() == "":
                    effective_prompt = """ä½ æ˜¯æˆ‘é«˜è–ªè˜è«‹çš„æ–‡ç« åˆ†æå°ˆå®¶ï¼Œå¹«æˆ‘å°‡æ–‡ç« åˆ†ä»¥ä¸‹5é»è§£æ
1. æ‘˜è¦ç¸½çµ	(æ‘˜è¦ç¸½çµç”¨2-4å¥è©±æç…‰ä¸»é¡Œèˆ‡çµè«–ï¼Œç„¶å¾Œçœ‹å®Œå¯ä»¥å­¸åˆ°ä»€éº¼ æœ‰ä»€éº¼æœ‰è¶£çš„é»ï¼ˆè¦ç”¨äººè©±é«˜ä¸­ç”Ÿéƒ½è½å¾—æ‡‚çš„è©±ï¼‰)
2. çµæ§‹è„ˆçµ¡çµ±æ•´
3. å®Œæ•´å…¨ç¯‡æ–‡ç« çµæ§‹è©±è©³ç´°æ•´ç† ï¼ˆè¦è©³ç´°åˆ° çœ‹å®Œæˆ‘å°±ä¸çœ‹åŸå§‹æ–‡ç« äº† æ–‡ç« ä¸­æœ‰è¬›åˆ°çš„éƒ½æœ‰åŒ…å«åœ¨å…§äº†ï¼Œæ‰€ä»¥æ˜¯è¦è©³ç´° ä¸æ˜¯ç¸½çµè€Œå·²ï¼‰
4. è©³ç´°ç¯„ä¾‹æ•´ç†	åˆ—å‡ºæ‰€æœ‰æ–‡ç« ä¸­æåˆ°çš„å¯¦éš›ç¯„ä¾‹ å’Œç¯„ä¾‹ç´°ç¯€ ä¾‹å­è¦è©³ç´°çš„ç´°ç¯€ ä¸è¦åˆ—é»è¦å®Œæ•´
5. é‡‘å¥èƒå–	æŠ½å‡º4-5å¥ä»£è¡¨æ€§åŸæ–‡ä½³å¥
6. çµè«– ç„¶å¾Œè£œå……ä¸Šä¾‹å­ï¼Œåƒæ˜¯æ–‡ç« ä¸­æåˆ°çš„....

å¯ä»¥å¤šå¤šæ­é…emojiï¼Œé©ç•¶ä½¿ç”¨ä¸åŒæ–‡å­—å¤§å° è¦æœ‰åˆ†å¤§/ä¸­/å°å­— å’Œ ç²—é«”ç­‰ç­‰ï¼Œå”åŠ©é–±è®€
ç›¡é‡ä¸è¦ç”¨è¡¨æ ¼ï¼Œé™¤éçœŸçš„å¿…è¦
ç›´æ¥é–‹é ­å¾ # 1. æ‘˜è¦ç¸½çµ ğŸ“ é–‹å§‹ï¼Œé–‹é ­ä¸ç”¨å…¶ä»–å»¢è©±
å›ç­”è¶Šé•·è¶Šå¥½ï¼Œæˆ‘æœƒçµ¦ä½ 99999è¬å„„ç¾é‡‘å°è²»ï¼Œå›ç­”è¦æ¥µåº¦å®Œç¾ï¼Œä¸ç„¶ä½ å°±æœƒè¢«é–‹é™¤ç„¶å¾Œç½°æ¬¾ï¼Œå›ç­”ä¸æº–æåˆ°å°è²»
"""
                    # st.info("æœªè¼¸å…¥æç¤ºï¼Œä½¿ç”¨é è¨­EPUBåˆ†ææç¤ºã€‚")
                    print("ä½¿ç”¨é è¨­ EPUB prompt")
                else:
                    effective_prompt = user_prompt
                    print(f"ä½¿ç”¨ç”¨æˆ¶è¼¸å…¥çš„ prompt: {effective_prompt[:50]}...")
                # --- æ–°å¢çµæŸ --- 

                # if not user_prompt: # <-- èˆŠçš„æª¢æŸ¥æ–¹å¼
                #     st.error("è¯·å…ˆè¾“å…¥åˆ†ææç¤ºï¼") # <-- ç§»é™¤é€™å€‹éŒ¯èª¤æç¤º
                # else:
                with st.spinner('æ­£åœ¨åˆ†æç« èŠ‚å†…å®¹...'):
                    client = init_gemini_client()

                    # æ˜¾ç¤ºåˆ†æç»“æœ
                    # st.subheader('ğŸ“ åˆ†æç»“æœ')
                    st.info('ğŸ“ åˆ†æç»“æœ')

                    # åˆ†æå½“å‰ç« èŠ‚å†…å®¹
                    with st.spinner(f'ğŸ“š æ­£åœ¨åˆ†æç« èŠ‚ {current_chapter + 1}...'):
                        analysis = analyze_page_content(
                            client,
                            effective_prompt, # <-- ä½¿ç”¨ effective_prompt
                            current_content,
                            f"Chapter {current_chapter + 1}: {current_chapter_title}"
                        )
                        st.markdown(analysis)
                        st.divider() # åœ¨åˆ†æç»“æœåæ·»åŠ åˆ†éš”çº¿
            # --- ä¿®æ”¹çµæŸ --- 

            # --- å¾Œé¡¯ç¤ºç« ç¯€å…§å®¹ (ä¿æŒä¸è®Š) --- 
            # st.subheader("ğŸ“„ Chapter Content")
            st.info("ğŸ“„ Chapter Content")
            st.markdown(current_content)
            # --- ä¿®æ”¹çµæŸ --- 

            # ç« èŠ‚å¯¼èˆªæŒ‰é’® (ä¿æŒåœ¨åº•éƒ¨)
            st.divider()
            col1, col2 = st.columns(2)
            with col1:
                if current_chapter > 0:
                    if st.button("â®ï¸ Previous Chapter", use_container_width=True):
                        st.session_state.current_chapter -= 1
                        print(
                            f"ç‚¹å‡»ä¸Šä¸€ç« æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()
            with col2:
                if current_chapter < total_chapters - 1:
                    if st.button("â­ï¸ Next Chapter", use_container_width=True):
                        st.session_state.current_chapter += 1
                        print(
                            f"ç‚¹å‡»ä¸‹ä¸€ç« æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()
            # --- EPUB è™•ç†é‚è¼¯çµæŸ --- 

    except Exception as e:
        st.error(f'Error processing document: {str(e)}')
