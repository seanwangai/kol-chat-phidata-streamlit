import streamlit as st
import fitz  # PyMuPDF
import io
import base64
from PIL import Image
from google import genai
from google.genai import types
from itertools import cycle
import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
import math
import re
from streamlit_pdf_viewer import pdf_viewer

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Document Reader & Analyzer",
    page_icon="ğŸ“š",
    layout="wide"
)

# åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
def get_next_api_key():
    """è·å–ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
    if "api_key_cycle" not in st.session_state:
        st.session_state.api_key_cycle = cycle(st.secrets["GOOGLE_API_KEYS"])
    return next(st.session_state.api_key_cycle)

def init_gemini_client():
    return genai.Client(
        api_key=get_next_api_key(),
    )

# PDFè½¬å›¾ç‰‡å‡½æ•°
def convert_pdf_to_images(pdf_document):
    images = []
    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        pix = page.get_pixmap()
        img_data = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        images.append(img)
    return images

# è¯»å–EPUBæ–‡ä»¶å¹¶æŒ‰ç« èŠ‚åˆ†å‰²
def read_epub_by_chapters(file_content):
    """è¯»å–EPUBæ–‡ä»¶å¹¶æŒ‰ç« èŠ‚åˆ†å‰²å†…å®¹"""
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        import tempfile
        import os
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.epub') as temp_file:
            temp_file.write(file_content)
            temp_file_path = temp_file.name
        
        try:
            # è¯»å–EPUBæ–‡ä»¶
            book = epub.read_epub(temp_file_path)
            
            # å­˜å‚¨ç« èŠ‚å†…å®¹
            chapters = []
            chapter_titles = []
            
            # éå†æ‰€æœ‰é¡¹ç›®ï¼Œæå–ç« èŠ‚å†…å®¹
            for item in book.get_items():
                if item.get_type() == ebooklib.ITEM_DOCUMENT:
                    # è§£æHTMLå†…å®¹
                    soup = BeautifulSoup(item.get_content(), 'html.parser')
                    
                    # å°è¯•è·å–ç« èŠ‚æ ‡é¢˜
                    title = soup.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                    chapter_title = title.get_text() if title else f"Chapter {len(chapters) + 1}"
                    
                    # è·å–ç« èŠ‚æ–‡æœ¬å†…å®¹
                    text = soup.get_text()
                    
                    # å¦‚æœç« èŠ‚å†…å®¹ä¸ä¸ºç©ºï¼Œåˆ™æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    if text.strip():
                        chapters.append(text)
                        chapter_titles.append(chapter_title)
            
            return chapters, chapter_titles
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_file_path)
            except:
                pass
    except Exception as e:
        st.error(f"è¯»å–EPUBæ–‡ä»¶å¤±è´¥: {str(e)}")
        return [], []

# è®¡ç®—æ–‡æœ¬å­—æ•°
def count_words(text):
    """è®¡ç®—æ–‡æœ¬ä¸­çš„å­—æ•°ï¼ˆä¸­æ–‡å­—ç¬¦ + è‹±æ–‡å•è¯ï¼‰"""
    # åŒ¹é…ä¸­æ–‡å­—ç¬¦
    chinese_characters = re.findall(r'[\u4e00-\u9fff]', text)
    # åŒ¹é…è‹±æ–‡å•è¯
    english_words = re.findall(r'\b[a-zA-Z]+\b', text)
    # è¿”å›ä¸­æ–‡å­—ç¬¦æ•° + è‹±æ–‡å•è¯æ•°
    return len(chinese_characters) + len(english_words)

# åˆ†ææ–‡æ¡£é¡µé¢å†…å®¹
def analyze_page_content(client, prompt, content, page_info):
    try:
        full_prompt = f"""{content}

{prompt}"""
        
        model = "gemini-2.0-flash-exp"
        contents = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=full_prompt)],
            ),
        ]

        response = client.models.generate_content(
            model=model,
            contents=contents,
        )
        
        return response.candidates[0].content.parts[0].text
    except Exception as e:
        return f"Analysis error: {str(e)}"

# Main page
st.title("ğŸ“š Document Analyzer")

# åˆå§‹åŒ–session state
if 'current_chapter' not in st.session_state:
    st.session_state.current_chapter = 0
    print(f"åˆå§‹åŒ– current_chapter: {st.session_state.current_chapter}")
if 'document_type' not in st.session_state:
    st.session_state.document_type = None
if 'epub_chapters' not in st.session_state:
    st.session_state.epub_chapters = []
if 'epub_chapter_titles' not in st.session_state:
    st.session_state.epub_chapter_titles = []

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader("Upload Document (PDF/EPUB)", type=["pdf", "epub"])

# æ·»åŠ ä¸€ä¸ªæ ‡è®°æ¥è·Ÿè¸ªæ–‡ä»¶æ˜¯å¦å·²ç»å¤„ç†è¿‡
if 'file_processed' not in st.session_state:
    st.session_state.file_processed = False
    print('file_processed', st.session_state.file_processed)

# åªæœ‰å½“æ–‡ä»¶ä¸Šä¼ ä¸”æœªå¤„ç†è¿‡ï¼Œæˆ–è€…æ–‡ä»¶å‘ç”Ÿå˜åŒ–æ—¶æ‰å¤„ç†æ–‡ä»¶
if uploaded_file is not None:
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å‘ç”Ÿå˜åŒ–
    current_file_name = uploaded_file.name
    print('current_file_name', current_file_name)
    print('====')
    print("'last_file_name' not in st.session_state", 'last_file_name' not in st.session_state)
    if 'last_file_name' not in st.session_state or st.session_state.last_file_name != current_file_name:
        st.session_state.last_file_name = current_file_name
        print('last_file_name', st.session_state.last_file_name)
        st.session_state.file_processed = False
        print('in uploaded_file file_processed', st.session_state.file_processed)
    
    if not st.session_state.file_processed:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            st.session_state.document_type = "pdf"
            # é‡ç½®EPUBç›¸å…³çŠ¶æ€
            st.session_state.epub_chapters = []
            st.session_state.epub_chapter_titles = []
            st.session_state.epub_pages = []
            st.session_state.current_chapter = 0
            st.session_state.current_page = 0
        elif file_extension == "epub":
            st.session_state.document_type = "epub"
            # è¯»å–EPUBæ–‡ä»¶
            epub_content = uploaded_file.read()
            st.session_state.epub_chapters, st.session_state.epub_chapter_titles = read_epub_by_chapters(epub_content)
            
            # è®¾ç½®åˆå§‹ç« èŠ‚
            if st.session_state.epub_chapters:
                st.session_state.current_chapter = 0
                print(f"ä¸Šä¼ EPUBæ–‡ä»¶åè®¾ç½® current_chapter: {st.session_state.current_chapter}")
        
        # æ ‡è®°æ–‡ä»¶å·²å¤„ç†
        st.session_state.file_processed = True
        print('file_processed', st.session_state.file_processed)

# åœ¨ä¾§è¾¹æ æ·»åŠ æç¤ºè¯è¾“å…¥å’Œæ–‡æ¡£é¢„è§ˆ
with st.sidebar:
    st.subheader("ğŸ’­ Analysis Prompt")
    user_prompt = st.text_area(
        "Enter analysis prompt",
        height=150,
        placeholder="Example: Summarize the main content of this page..."
    )
    
    # æ·»åŠ é¡µé¢æ‰¹é‡åˆ†æé€‰é¡¹
    pages_per_batch = st.number_input(
        "Pages per analysis batch",
        min_value=1,
        max_value=100,
        value=1,
        help="Select how many pages to analyze together. Higher values mean fewer API calls but may affect analysis quality."
    )
    
    # æ·»åŠ ä¸€ä¸ªç¾è§‚çš„EnteræŒ‰é’®
    if st.button("Enter", type="primary", use_container_width=True):
        st.session_state.analyze_trigger = True
    
    # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ–‡æ¡£é¢„è§ˆ
    if uploaded_file is not None:
        try:
            if st.session_state.document_type == "pdf":
                # è¯»å–PDFæ–‡ä»¶
                pdf_bytes = uploaded_file.read()
                pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
                
                pdf_viewer(pdf_bytes)


            
            elif st.session_state.document_type == "epub" and st.session_state.epub_chapters:
                # æ˜¾ç¤ºEPUBç« èŠ‚å¯¼èˆªå’Œå­—æ•°ç»Ÿè®¡
                st.subheader("ğŸ“‘ Chapters")
                for i, (title, content) in enumerate(zip(st.session_state.epub_chapter_titles, st.session_state.epub_chapters)):
                    word_count = count_words(content)
                    if st.button(f"{title} ({word_count} å­—)", key=f"chapter_{i}", use_container_width=True):
                        st.session_state.current_chapter = i
                        print(f"ç‚¹å‡»ç« èŠ‚æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()

        except Exception as e:
            st.error(f'Error displaying document: {str(e)}')

# ä¸»å†…å®¹åŒºåŸŸ
if uploaded_file is not None:
    try:
        if st.session_state.document_type == "pdf":
            # è¯»å–PDFæ–‡ä»¶ï¼ˆå¦‚æœè¿˜æ²¡æœ‰è¯»å–ï¼‰
            if 'pdf_document' not in locals():
                pdf_bytes = uploaded_file.read()
                pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
            
            # æ˜¾ç¤ºPDFä¿¡æ¯
            st.subheader(f"ğŸ“„ PDF Document - {pdf_document.page_count} pages")
            
            # è·å–å½“å‰é¡µé¢çš„æ–‡æœ¬å†…å®¹ç”¨äºåˆ†æ
            if user_prompt:
                with st.spinner('Analyzing page content...'):
                    client = init_gemini_client()
                    
                    # Display analysis results below the PDF
                    st.subheader('ğŸ“ Analysis Results')
                    
                    # è®¡ç®—éœ€è¦å¤„ç†çš„æ‰¹æ¬¡æ•°
                    total_pages = pdf_document.page_count
                    batch_count = (total_pages + pages_per_batch - 1) // pages_per_batch
                    
                    # æŒ‰æ‰¹æ¬¡å¤„ç†é¡µé¢
                    for batch in range(batch_count):
                        start_page = batch * pages_per_batch
                        end_page = min(start_page + pages_per_batch, total_pages)
                        
                        with st.spinner(f'ğŸ“š Analyzing pages {start_page + 1} to {end_page}...'):
                            # åˆå¹¶è¿™æ‰¹é¡µé¢çš„æ–‡æœ¬
                            batch_text = ""
                            for page_num in range(start_page, end_page):
                                batch_text += pdf_document[page_num].get_text() + "\n\n"
                            
                            # åˆ†æåˆå¹¶åçš„å†…å®¹
                            analysis = analyze_page_content(client, user_prompt, batch_text, f"PDF Pages {start_page + 1}-{end_page}")
                            
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            # st.markdown(f"### ğŸ“š Pages {start_page + 1} to {end_page} Analysis")
                            if start_page + 1 == end_page:
                                st.success(f"Page {start_page + 1} Analysis", icon="ğŸ“š")
                            else:
                                st.success(f"Pages {start_page + 1} to {end_page} Analysis", icon="ğŸ“š")
                            st.markdown(analysis)
                            st.markdown("---")  # Add separator
        
        elif st.session_state.document_type == "epub" and st.session_state.epub_chapters:
            # æ˜¾ç¤ºEPUBä¿¡æ¯
            total_chapters = len(st.session_state.epub_chapters)
            current_chapter = st.session_state.current_chapter
            current_chapter_title = st.session_state.epub_chapter_titles[current_chapter]
            current_content = st.session_state.epub_chapters[current_chapter]
            
            st.subheader(f"ğŸ“– {current_chapter_title}")
            st.caption(f"å­—æ•°ï¼š{count_words(current_content)}")
            
            # å¦‚æœæœ‰æç¤ºè¯ä¸”ç‚¹å‡»äº†EnteræŒ‰é’®ï¼Œæ‰æ˜¾ç¤ºåˆ†æç»“æœ
            if user_prompt and st.session_state.get("analyze_trigger", False):
                with st.spinner('Analyzing content...'):
                    client = init_gemini_client()
                    
                    # æ˜¾ç¤ºåˆ†æç»“æœ
                    st.subheader('ğŸ“ Analysis Results')
                    
                    # åˆ†æå½“å‰ç« èŠ‚å†…å®¹
                    with st.spinner(f'ğŸ“š Analyzing chapter {current_chapter + 1}...'):
                        analysis = analyze_page_content(client, user_prompt, current_content, f"Chapter {current_chapter + 1}: {current_chapter_title}")
                        st.markdown(analysis)
                        st.markdown("---")  # Add separator
                # é‡ç½®åˆ†æè§¦å‘å™¨
                st.session_state.analyze_trigger = False
            
            # æ˜¾ç¤ºå½“å‰ç« èŠ‚å†…å®¹
            st.subheader("ğŸ“„ Chapter Content")
            st.markdown(current_content)
            st.markdown("---")
            
            # ç« èŠ‚å¯¼èˆªæŒ‰é’®
            col1, col2 = st.columns(2)
            with col1:
                if current_chapter > 0:
                    if st.button("â®ï¸ Previous Chapter"):
                        st.session_state.current_chapter -= 1
                        print(f"ç‚¹å‡»ä¸Šä¸€ç« æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()
            with col2:
                if current_chapter < total_chapters - 1:
                    if st.button("â­ï¸ Next Chapter"):
                        st.session_state.current_chapter += 1
                        print(f"ç‚¹å‡»ä¸‹ä¸€ç« æŒ‰é’®ï¼Œè®¾ç½® current_chapter: {st.session_state.current_chapter}")
                        st.rerun()
    except Exception as e:
        st.error(f'Error processing document: {str(e)}')