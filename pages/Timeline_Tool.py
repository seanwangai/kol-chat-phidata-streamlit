import streamlit as st
import requests
from datetime import datetime
from typing import List, Dict, Tuple
import json
from google import genai
from google.genai import types
from streamlit_timeline import st_timeline
from itertools import cycle
import pandas as pd

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Earnings Call Timeline",
    page_icon="ğŸ“Š",
    layout="wide"
)

# API é…ç½®
API_KEY = st.secrets["API_NINJAS_KEY"]
API_URL = 'https://api.api-ninjas.com/v1/earningstranscript'

# åˆå§‹åŒ–APIå¯†é’¥è½®æ¢
if "api_key_cycle" not in st.session_state:
    st.session_state.api_key_cycle = cycle(st.secrets["GOOGLE_API_KEYS"])

def get_next_api_key():
    """è·å–ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
    return next(st.session_state.api_key_cycle)

class EarningsCallFetcher:
    """è·å–è´¢æŠ¥ç”µè¯ä¼šè®®è®°å½•çš„ç±»"""

    def __init__(self, api_key):
        self.api_key = api_key
        self.headers = {'X-Api-Key': api_key}

    def get_transcript(self, ticker: str, year: int = None, quarter: int = None) -> dict:
        """è·å–æŒ‡å®šå…¬å¸å’Œå­£åº¦çš„è´¢æŠ¥ç”µè¯ä¼šè®®è®°å½•"""
        try:
            params = {'ticker': ticker}
            if year is not None:
                params['year'] = year
            if quarter is not None:
                params['quarter'] = quarter

            response = requests.get(
                API_URL,
                headers=self.headers,
                params=params
            )

            if response.status_code == 200:
                data = response.json()
                if isinstance(data, list) and data:
                    return data[0]
                return data
            else:
                st.error(f"è·å–è´¢æŠ¥å¤±è´¥: {response.status_code}")
                return None
        except Exception as e:
            st.error(f"è·å–è´¢æŠ¥æ—¶å‡ºé”™: {str(e)}")
            return None

    def get_all_transcripts_since_2024(self, ticker: str) -> List[Dict]:
        """è·å–ä»2024å¹´è‡³ä»Šçš„æ‰€æœ‰è´¢æŠ¥è®°å½•"""
        transcripts = []
        current_year = datetime.now().year

        # ä»2024å¹´å¼€å§‹ï¼ŒæŒ‰å¹´å’Œå­£åº¦é¡ºåºè·å–
        for year in range(2024, current_year + 1):
            # !!!!!!!!!
            # for quarter in range(1, 5):
            for quarter in range(4, 5):
                # st.write(f"å°è¯•è·å– {year} å¹´ Q{quarter} çš„è´¢æŠ¥...")

                transcript = self.get_transcript(ticker, year, quarter)

                # å¦‚æœè·å–å¤±è´¥ï¼Œè¯´æ˜è¿™ä¸ªå­£åº¦çš„è´¢æŠ¥è¿˜æ²¡æœ‰ï¼Œå°±åœæ­¢è·å–
                if not transcript:
                    st.info(f"æœªæ‰¾åˆ° {year} å¹´ Q{quarter} çš„è´¢æŠ¥ï¼Œåœæ­¢è·å–")
                    return transcripts

                transcripts.append({
                    'year': year,
                    'quarter': quarter,
                    'content': transcript
                })
                st.success(f"æˆåŠŸè·å– {year} å¹´ Q{quarter} çš„è´¢æŠ¥")

        return transcripts


def analyze_transcript_topics(transcript: str) -> List[str]:
    """ä½¿ç”¨ Gemini åˆ†æè´¢æŠ¥ä¸­çš„é‡ç‚¹ä¸šåŠ¡ä¸»é¢˜"""
    try:
        # st.write("å¼€å§‹åˆ†æè´¢æŠ¥å†…å®¹...")
        if not transcript or len(transcript.strip()) < 100:
            st.warning("è´¢æŠ¥å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return []

        client = genai.Client(
            api_key=get_next_api_key(),
        )

        prompt = f"""
åˆ†æä»¥ä¸‹è´¢æŠ¥ç”µè¯ä¼šè®®è®°å½•ï¼Œæå–é‡ç‚¹ä¸šåŠ¡ä¸»é¢˜ï¼Œæ˜¯å…¬å¸é‡é»æœ‰æåˆ° å’Œ æœ€å¾Œçš„Q&Aåˆ†æå¸«é—œå¿ƒçš„ä¸»é¢˜ï¼Œå°±æ˜¯è¼¸å‡ºå¤§å®¶é—œå¿ƒçš„å…·é«”æ¥­å‹™åå°±å¥½

{transcript}

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼Œæ ¼å¼ä¸ºï¼š
{{"topic": ["ä¸»é¢˜1", "ä¸»é¢˜2", "ä¸»é¢˜3"]}}
"""

        model = "gemini-2.0-flash-exp"
        contents = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)],
            ),
        ]

        generate_content_config = types.GenerateContentConfig(
            temperature=0.7,
            top_p=0.95,
            top_k=40,
            max_output_tokens=8192,
            response_mime_type="application/json",
            response_schema=genai.types.Schema(
                type=genai.types.Type.OBJECT,
                properties={
                    "topic": genai.types.Schema(
                        type=genai.types.Type.ARRAY,
                        items=genai.types.Schema(
                            type=genai.types.Type.STRING,
                        ),
                    ),
                },
            ),
        )

        # st.write("æ­£åœ¨è°ƒç”¨ Gemini API...")
        response = client.models.generate_content(
            model=model,
            contents=contents,
            config=generate_content_config,
        )

        # æ‰“å°åŸå§‹å“åº”ä»¥ä¾¿è°ƒè¯•
        # st.write("Gemini è¿”å›åŸå§‹å“åº”ï¼š", response.candidates[0].content)

        # å°è¯•ä»å“åº”ä¸­æå–æ–‡æœ¬
        try:
            # è·å–å“åº”ä¸­çš„ç¬¬ä¸€ä¸ª part çš„æ–‡æœ¬
            response_text = response.candidates[0].content.parts[0].text
            # st.write("è§£æå“åº”æ–‡æœ¬ï¼š", response_text)

            # è§£æ JSON
            # print('ä¸»é¢˜json')
            # print(response_text)
            response_json = json.loads(response_text)
            return response_json.get("topic", [])

        except AttributeError as e:
            st.error(f"å“åº”æ ¼å¼ä¸æ­£ç¡®: {str(e)}")
            # å°è¯•ç›´æ¥ä» content ä¸­è·å–
            try:
                if hasattr(response.candidates[0].content, "topic"):
                    return response.candidates[0].content.topic
                else:
                    st.error("æ— æ³•ä»å“åº”ä¸­æå–ä¸»é¢˜")
                    return []
            except Exception as e2:
                st.error(f"å¤‡é€‰æå–æ–¹æ³•ä¹Ÿå¤±è´¥: {str(e2)}")
                return []

        except json.JSONDecodeError as e:
            st.error(f"JSON è§£æå¤±è´¥: {str(e)}")
            return []

        except Exception as e:
            st.error(f"å¤„ç†å“åº”æ—¶å‡ºé”™: {str(e)}")
            return []

    except Exception as e:
        st.error(f"åˆ†æä¸»é¢˜æ—¶å‡ºé”™: {str(e)}")
        return []


def get_monthly_news(client: genai.Client, company_name: str, topic: str, year: int, month: int) -> List[Dict]:
    """è·å–ç‰¹å®šæœˆä»½çš„ä¸»é¢˜æ–°é—»"""
    try:
        prompt = f""" ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æŠ•è³‡äººï¼Œè¯·æœç´¢å¹¶æ€»ç»“ "{company_name}" å…¬å¸æœ‰å…³æ–¼  '{topic}'ã€‚åœ¨ {year}å¹´{month}æœˆ æ–°ç™¼ç”Ÿçš„æ–°çš„é‡å¤§äº‹ä»¶å’Œè¨è«–å€æœ‰åœ¨è¨è«–çš„ï¼Œæˆ–æ˜¯ç™¼è¡¨çš„æ–°ç”¢å“ï¼Œä½†æ˜¯å¦‚æœè²¡å ±ä¸­æœ‰èªªåˆ°çš„å°±ä¸ç”¨äº†ï¼Œjson event å…§æ–‡ç¸½çµæˆæŠ•è³‡äººæœƒæƒ³çœ‹çš„é‡é»ï¼Œç„¶å¾Œé‡é»å…ˆè¡Œï¼Œä»¥ä¸­æ–‡å›ç­”
æ³¨æ„ ä¸€å®šè¦è·Ÿ '{topic}' æœ‰é—œçš„
ä¸€å®šè¦ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹:
[{{"date": "2025-01-15","event": "äº‹ä»¶ç®€çŸ­æè¿°","group": "{topic}"}},]
"""

        contents = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)],
            ),
        ]

        tools = [types.Tool(google_search=types.GoogleSearch())]
        generate_content_config = types.GenerateContentConfig(
            temperature=0.7,
            top_p=0.95,
            top_k=40,
            max_output_tokens=8192,
            tools=tools,
            response_mime_type="text/plain",
        )

        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=contents,
            config=generate_content_config,
        )
        print('==model res==')
        print(response.candidates[0].content)
        # !!!!!!
        # try:
        #     response_text = response.candidates[0].content.parts[1].text
        #     print('=== in get_monthly_news===')
        #     cleaned_text = response_text.strip()
        #     print(cleaned_text)
        #     print(type(cleaned_text))
        #     return json.loads(cleaned_text)
        # except (AttributeError, json.JSONDecodeError) as e:
        #     print('===GGGGGGG in get_monthly_news===')
        #     print(e)
        #     return []
        response_text = response.candidates[0].content.parts[1].text
        print('=== in get_monthly_news===')
        print(type(response_text))
        # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½çš„JSONæ ¼å¼æ ‡è®°
        cleaned_text = response_text.strip()
        if cleaned_text.startswith('```json'):
            cleaned_text = cleaned_text[7:]
        if cleaned_text.endswith('```'):
            cleaned_text = cleaned_text[:-3]
        cleaned_text = cleaned_text.strip()
        print(cleaned_text)
        print(type(cleaned_text))
        return json.loads(cleaned_text)

    except Exception as e:
        print(f"è·å– {year}å¹´{month}æœˆæ–°é—»æ—¶å‡ºé”™: {str(e)}")
        return []


def get_topic_news(topic: str, ticker: str) -> List[Dict]:
    """æŒ‰æœˆä»½è·å–ä¸»é¢˜çš„æœ€æ–°æ¶ˆæ¯"""
    try:
        # st.write(f"å¼€å§‹è·å– '{topic}' çš„æœˆåº¦æ–°é—»...")

        client = genai.Client(
            api_key=get_next_api_key(),
        )

        current_date = datetime.now()
        current_year = current_date.year
        current_month = current_date.month

        all_events = []

        for year in range(2025, current_year + 1):
            end_month = 12 if year < current_year else current_month
            for month in range(1, end_month + 1):
                # st.write(f"æ­£åœ¨è·å– {year}å¹´{month}æœˆ çš„æ–°é—»...")
                monthly_events = get_monthly_news(client, ticker, topic, year, month)
                all_events.extend(monthly_events)

        return all_events

    except Exception as e:
        st.error(f"è·å–ä¸»é¢˜æ–°é—»æ—¶å‡ºé”™: {str(e)}")
        return []

# åˆå§‹åŒ– session state
if "transcripts_data" not in st.session_state:
    st.session_state.transcripts_data = {}
if "topics_data" not in st.session_state:
    st.session_state.topics_data = {}

# ä¸»é¡µé¢
st.title("ğŸ“Š è´¢æŠ¥ç”µè¯ä¼šè®®æ—¶é—´çº¿åˆ†æ")

# æ·»åŠ è‚¡ç¥¨ä»£ç è¾“å…¥
ticker = st.text_input(
    "è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆä¾‹å¦‚ï¼šAAPLï¼‰",
    key="timeline_ticker_input"
).upper()

if ticker:
    if st.button("ğŸ“ˆ åˆ†æè´¢æŠ¥æ—¶é—´çº¿", type="primary"):
        with st.spinner(f"æ­£åœ¨è·å–å¹¶åˆ†æ {ticker} çš„è´¢æŠ¥è®°å½•..."):
            fetcher = EarningsCallFetcher(API_KEY)
            transcripts = fetcher.get_all_transcripts_since_2024(ticker)

            if transcripts:
                st.session_state.transcripts_data = transcripts
                st.write(f"æˆåŠŸè·å– {len(transcripts)} ä»½è´¢æŠ¥è®°å½•")

                all_transcripts_text = ""
                for transcript_data in transcripts:
                    year = transcript_data['year']
                    quarter = transcript_data['quarter']
                    content = transcript_data['content'].get('transcript', '')
                    if content:
                        all_transcripts_text += f"\n\n=== {year}å¹´ Q{quarter} ===\n{content}"

                st.subheader("ğŸ” åˆ†ææ‰€æœ‰å­£åº¦çš„é‡ç‚¹ä¸šåŠ¡ä¸»é¢˜")
                all_topics = []
                if all_transcripts_text:
                    all_topics = analyze_transcript_topics(all_transcripts_text)
                    print(all_topics)

                    if all_topics:
                        st.success(f"ä»æ‰€æœ‰å­£åº¦ä¸­å‘ç° {len(all_topics)} ä¸ªä¸»é¢˜")
                        # æ˜¾ç¤ºæ‰€æœ‰å‘ç°çš„ä¸»é¢˜
                        st.write("ğŸ“Œ å‘ç°çš„ä¸»é¢˜ï¼š")
                        for topic in all_topics:
                            st.markdown(f"- {topic}")

                        st.subheader("ğŸ“Œ é‡ç‚¹ä¸šåŠ¡ä¸»é¢˜åˆ†æ")
                        
                        # æ”¶é›†æ‰€æœ‰ä¸»é¢˜çš„äº‹ä»¶æ•°æ®
                        all_events = []
                        groups = []
                        for i, topic in enumerate(all_topics, 1):
                            st.markdown(f"### ğŸ” {topic}")
                            with st.spinner(f"æ­£åœ¨è·å– {topic} çš„æœ€æ–°åŠ¨æ€..."):
                                events = get_topic_news(topic, ticker)
                                print('==event==') 
                                print(events)
                                all_events.extend(events)
                                
                                # æ˜¾ç¤ºå½“å‰ä¸»é¢˜çš„äº‹ä»¶è¡¨æ ¼
                                if events:
                                    st.write(f"ğŸ“‹ {topic}ç›¸å…³äº‹ä»¶è¡¨æ ¼ï¼š")
                                    # åˆ›å»ºä¸€ä¸ªæ›´ç¾è§‚çš„DataFrame
                                    events_df = pd.DataFrame(events)
                                    # æŒ‰æ—¥æœŸæ’åº
                                    events_df = events_df.sort_values('date')
                                    # é‡å‘½ååˆ—ä»¥ä¾¿æ›´ç›´è§‚
                                    events_df = events_df[['date', 'event']]
                                    events_df.columns = ["æ—¥æœŸ", "äº‹ä»¶æè¿°"]
                                    # åº”ç”¨æ ·å¼å¹¶æ˜¾ç¤º
                                    st.dataframe(
                                        events_df,
                                        column_config={
                                            "æ—¥æœŸ": st.column_config.DateColumn("æ—¥æœŸ", format="YYYY-MM-DD"),
                                            "äº‹ä»¶æè¿°": st.column_config.TextColumn("äº‹ä»¶æè¿°", width="large"),
                                        },
                                        use_container_width=True,
                                        hide_index=True,
                                    )
                                else:
                                    st.info(f"æœªæ‰¾åˆ°ä¸ {topic} ç›¸å…³çš„æœ€æ–°äº‹ä»¶")

                                # ä¸ºæ¯ä¸ªä¸»é¢˜åˆ›å»ºä¸€ä¸ªåˆ†ç»„
                                # ä½¿ç”¨ç°ä»£åŒ–çš„é…è‰²æ–¹æ¡ˆ - 20ç§å¸¦é€æ˜åº¦çš„å•è‰²
                                modern_colors = [
                                    "rgba(65, 88, 208, 0.8)",    # ç´«è“è‰²
                                    "rgba(0, 147, 233, 0.8)",    # è“è‰²
                                    "rgba(142, 197, 252, 0.8)",  # æ·¡è“è‰²
                                    "rgba(251, 171, 126, 0.8)",  # æ©™è‰²
                                    "rgba(133, 255, 189, 0.8)",  # ç»¿è‰²
                                    "rgba(255, 154, 139, 0.8)",  # ç²‰çº¢è‰²
                                    "rgba(169, 201, 255, 0.8)",  # æµ…è“è‰²
                                    "rgba(33, 212, 253, 0.8)",   # é’è‰²
                                    "rgba(250, 139, 255, 0.8)",  # ç²‰è‰²
                                    "rgba(8, 174, 234, 0.8)",    # è“ç»¿è‰²
                                    "rgba(254, 225, 64, 0.8)",   # é»„è‰²
                                    "rgba(255, 60, 172, 0.8)",   # æ´‹çº¢è‰²
                                    "rgba(255, 154, 158, 0.8)",  # çŠç‘šè‰²
                                    "rgba(0, 219, 222, 0.8)",    # é’ç»¿è‰²
                                    "rgba(246, 211, 101, 0.8)",  # é‡‘è‰²
                                    "rgba(252, 207, 49, 0.8)",   # é»„æ©™è‰²
                                    "rgba(67, 233, 123, 0.8)",   # ç»¿æ¾çŸ³è‰²
                                    "rgba(102, 126, 234, 0.8)",  # é›è“è‰²
                                    "rgba(244, 59, 71, 0.8)",    # çº¢è‰²
                                    "rgba(110, 69, 226, 0.8)",   # ç´«è‰²
                                ]
                                color_index = i % len(modern_colors) if modern_colors else 0
                                groups.append({
                                    "id": str(i),
                                    "content": topic,
                                    "style": f"color: white; background: {modern_colors[color_index]}; padding: 8px; border-radius: 6px; font-weight: 500; box-shadow: 0 2px 5px rgba(0,0,0,0.1);"
                                })
                            st.markdown("---")

                        # è½¬æ¢äº‹ä»¶æ•°æ®ä¸ºæ—¶é—´è½´æ ¼å¼ï¼Œå¹¶æŒ‰æ—¶é—´æ’åº
                        timeline_items = []
                        for i, event in enumerate(all_events):
                            timeline_items.append({
                                "id": i + 1,
                                "content": event['event'],
                                "start": f"{event['date']}T00:00:00",
                                "group": str(all_topics.index(event['group']) + 1)
                            })
                        # æŒ‰æ—¶é—´æ’åº
                        timeline_items.sort(key=lambda x: x['start'])
                        print('==============')
                        print(timeline_items)
                        print('=======groups=======')
                        print(groups)
                        # æ˜¾ç¤ºæ—¶é—´è½´
                        st.subheader("ğŸ“… äº‹ä»¶æ—¶é—´è½´")
                        
                        # æ ¹æ®åˆ†ç»„æ•°é‡å’Œæ¯ä¸ªåˆ†ç»„å†…çš„é¡¹ç›®æ•°é‡åŠ¨æ€è®¡ç®—æ—¶é—´è½´é«˜åº¦
                        # ç›´æ¥æ ¹æ®é¡¹ç›®æ•°é‡åŠ¨æ€è°ƒæ•´é«˜åº¦
                        # ä¸ºæ¯ä¸ªé¡¹ç›®åˆ†é…50pxçš„é«˜åº¦ï¼Œå†åŠ ä¸ŠåŸºç¡€é«˜åº¦200px
                        dynamic_height = max(600, len(timeline_items) * 50)
                        
                        timeline = st_timeline(
                            timeline_items,
                            groups=groups,
                            options={
                                "selectable": True,
                                "multiselect": True,
                                "zoomable": True,
                                "verticalScroll": True,
                                "stack": True,
                                "height": dynamic_height,  # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„é«˜åº¦
                                "margin": {"axis": 5, "item": {"vertical": 15}},
                                "groupHeightMode": "fixed",
                                "groupMinWidth": 100,  # è®¾ç½®åˆ†ç»„åˆ—çš„æœ€å°å®½åº¦
                                "groupMaxWidth": 120,  # è®¾ç½®åˆ†ç»„åˆ—çš„æœ€å¤§å®½åº¦
                                "orientation": {"axis": "both", "item": "top"},
                                "align": "left",
                                "itemsAlwaysDraggable": True,
                                "showMajorLabels": True,
                                "showMinorLabels": True
                            }
                        )

                        if timeline:
                            st.write("é€‰ä¸­çš„äº‹ä»¶ï¼š", timeline)

                        # æ˜¾ç¤ºå„å­£åº¦åŸå§‹å†…å®¹
                        st.subheader("ğŸ“‘ å„å­£åº¦è´¢æŠ¥è¯¦æƒ…")
                        for transcript_data in transcripts:
                            year = transcript_data['year']
                            quarter = transcript_data['quarter']
                            content = transcript_data['content'].get('transcript', '')

                            with st.expander(f"ğŸ“… {year}å¹´ Q{quarter}"):
                                if content:
                                    st.write(f"å†…å®¹é•¿åº¦ï¼š{len(content)} å­—ç¬¦")
                                    st.markdown(content)
                                else:
                                    st.warning("è´¢æŠ¥å†…å®¹ä¸ºç©º")

                    else:
                        st.warning("æœªèƒ½ä»æ‰€æœ‰å­£åº¦ä¸­æå–åˆ°ä¸»é¢˜")

            else:
                st.error("æœªæ‰¾åˆ°ä»»ä½•è´¢æŠ¥è®°å½•")
